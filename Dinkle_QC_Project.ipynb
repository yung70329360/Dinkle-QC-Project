{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yung70329360/Dinkle-QC-Project/blob/main/Dinkle_QC_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "WVQf1VY2eulj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8050b6c-36bc-4090-bf8a-1a77aa5f8896"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "tp1Zy5SQe97H"
      },
      "outputs": [],
      "source": [
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Circle\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from datetime import datetime\n",
        "import sys\n",
        "import os\n",
        "import random\n",
        "from argparse import ArgumentParser\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder, Normalizer, StandardScaler, MinMaxScaler \n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.autograd import Variable\n",
        "from torch.distributions.beta import Beta\n",
        "\n",
        "from google.colab import drive\n",
        "from random import sample\n",
        "import random\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14s6zkqNfm3K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d84650f-522d-464b-87d5-9d902875c87b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data machine: (222680, 15)\n",
            "data rate: (5218, 33)\n",
            "data rate old: (566, 28)\n"
          ]
        }
      ],
      "source": [
        "data_machine = pd.read_csv('/content/drive/MyDrive/羅明秀_大數據品管/2022_03_03_Data.csv')\n",
        "data_rate_old = pd.read_csv('/content/drive/MyDrive/羅明秀_大數據品管/0309.csv')\n",
        "data_rate = pd.read_csv('/content/drive/MyDrive/羅明秀_大數據品管/振動儀/瞬測儀0221B02700.csv')\n",
        "# print(data_rate)\n",
        "data_machine = data_machine[data_machine['product'] =='0162B00100'].dropna()\n",
        "data_rate_old = data_rate_old[data_rate_old['料號'] == '0162B00100'].dropna()\n",
        "data_rate = data_rate[data_rate['LotNo'] == '0162B00100']\n",
        "\n",
        "print('data machine:', data_machine.shape)\n",
        "print('data rate:', data_rate.shape)\n",
        "print('data rate old:', data_rate_old.shape)\n",
        "# print(data_rate)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mewmcp8LzsKw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9ad7729d-7df4-4301-c033-48e4b05d203b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                             編號      Date  DayNight    OrderNo     product  \\\n",
            "3589    2020102608:01_101181728  20201026         1  101181728  0162B00100   \n",
            "3590    2020102608:02_101181728  20201026         1  101181728  0162B00100   \n",
            "3591    2020102608:03_101181728  20201026         1  101181728  0162B00100   \n",
            "3592    2020102608:04_101181728  20201026         1  101181728  0162B00100   \n",
            "3593    2020102608:05_101181728  20201026         1  101181728  0162B00100   \n",
            "...                         ...       ...       ...        ...         ...   \n",
            "351140  2021111609:53_200006806  20211116         0  200006806  0162B00100   \n",
            "351141  2021111609:54_200006806  20211116         0  200006806  0162B00100   \n",
            "351142  2021111609:55_200006806  20211116         0  200006806  0162B00100   \n",
            "351143  2021111609:56_200006806  20211116         0  200006806  0162B00100   \n",
            "351144  2021111609:57_200006806  20211116         0  200006806  0162B00100   \n",
            "\n",
            "                       time     no  ProdCount  Speed  Status  Weight  \\\n",
            "3589    10/26/2020 08:01:59  D-001        392  310.0     2.0  6499.6   \n",
            "3590    10/26/2020 08:02:59  D-001        700  310.0     2.0  6499.6   \n",
            "3591    10/26/2020 08:03:59  D-001       1008  310.0     2.0  6499.2   \n",
            "3592    10/26/2020 08:04:59  D-001       1316  310.0     2.0  6499.2   \n",
            "3593    10/26/2020 08:05:59  D-001       1625  310.0     2.0  6499.0   \n",
            "...                     ...    ...        ...    ...     ...     ...   \n",
            "351140  11/16/2021 09:53:11  D-005     227410  301.0     2.0  6486.4   \n",
            "351141  11/16/2021 09:54:11  D-005     227638  301.0     2.0  6487.8   \n",
            "351142  11/16/2021 09:55:11  D-005     227940  301.0     2.0  6486.2   \n",
            "351143  11/16/2021 09:56:11  D-005     228244  301.0     2.0  6488.2   \n",
            "351144  11/16/2021 09:57:11  D-005     228547  301.0     2.0  6489.6   \n",
            "\n",
            "                   nonono                 Unnamed: 12  lagProdCount  frequency  \n",
            "3589    101181728_D-001_1  20201026_101181728_D-001_1            83   5.150000  \n",
            "3590    101181728_D-001_1  20201026_101181728_D-001_1           392   5.133333  \n",
            "3591    101181728_D-001_1  20201026_101181728_D-001_1           700   5.133333  \n",
            "3592    101181728_D-001_1  20201026_101181728_D-001_1          1008   5.133333  \n",
            "3593    101181728_D-001_1  20201026_101181728_D-001_1          1316   5.150000  \n",
            "...                   ...                         ...           ...        ...  \n",
            "351140  200006806_D-005_0  20211116_200006806_D-005_0        227107   5.050000  \n",
            "351141  200006806_D-005_0  20211116_200006806_D-005_0        227410   3.800000  \n",
            "351142  200006806_D-005_0  20211116_200006806_D-005_0        227638   5.033333  \n",
            "351143  200006806_D-005_0  20211116_200006806_D-005_0        227940   5.066667  \n",
            "351144  200006806_D-005_0  20211116_200006806_D-005_0        228244   5.050000  \n",
            "\n",
            "[222680 rows x 15 columns]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                             編號      Date  DayNight    OrderNo     product  \\\n",
              "3589    2020102608:01_101181728  20201026         1  101181728  0162B00100   \n",
              "3590    2020102608:02_101181728  20201026         1  101181728  0162B00100   \n",
              "3591    2020102608:03_101181728  20201026         1  101181728  0162B00100   \n",
              "3592    2020102608:04_101181728  20201026         1  101181728  0162B00100   \n",
              "3593    2020102608:05_101181728  20201026         1  101181728  0162B00100   \n",
              "...                         ...       ...       ...        ...         ...   \n",
              "351140  2021111609:53_200006806  20211116         0  200006806  0162B00100   \n",
              "351141  2021111609:54_200006806  20211116         0  200006806  0162B00100   \n",
              "351142  2021111609:55_200006806  20211116         0  200006806  0162B00100   \n",
              "351143  2021111609:56_200006806  20211116         0  200006806  0162B00100   \n",
              "351144  2021111609:57_200006806  20211116         0  200006806  0162B00100   \n",
              "\n",
              "                       time     no  ProdCount  Speed  Weight  \\\n",
              "3589    10/26/2020 08:01:59  D-001        392  310.0  6499.6   \n",
              "3590    10/26/2020 08:02:59  D-001        700  310.0  6499.6   \n",
              "3591    10/26/2020 08:03:59  D-001       1008  310.0  6499.2   \n",
              "3592    10/26/2020 08:04:59  D-001       1316  310.0  6499.2   \n",
              "3593    10/26/2020 08:05:59  D-001       1625  310.0  6499.0   \n",
              "...                     ...    ...        ...    ...     ...   \n",
              "351140  11/16/2021 09:53:11  D-005     227410  301.0  6486.4   \n",
              "351141  11/16/2021 09:54:11  D-005     227638  301.0  6487.8   \n",
              "351142  11/16/2021 09:55:11  D-005     227940  301.0  6486.2   \n",
              "351143  11/16/2021 09:56:11  D-005     228244  301.0  6488.2   \n",
              "351144  11/16/2021 09:57:11  D-005     228547  301.0  6489.6   \n",
              "\n",
              "                   nonono                 Unnamed: 12  lagProdCount  \\\n",
              "3589    101181728_D-001_1  20201026_101181728_D-001_1            83   \n",
              "3590    101181728_D-001_1  20201026_101181728_D-001_1           392   \n",
              "3591    101181728_D-001_1  20201026_101181728_D-001_1           700   \n",
              "3592    101181728_D-001_1  20201026_101181728_D-001_1          1008   \n",
              "3593    101181728_D-001_1  20201026_101181728_D-001_1          1316   \n",
              "...                   ...                         ...           ...   \n",
              "351140  200006806_D-005_0  20211116_200006806_D-005_0        227107   \n",
              "351141  200006806_D-005_0  20211116_200006806_D-005_0        227410   \n",
              "351142  200006806_D-005_0  20211116_200006806_D-005_0        227638   \n",
              "351143  200006806_D-005_0  20211116_200006806_D-005_0        227940   \n",
              "351144  200006806_D-005_0  20211116_200006806_D-005_0        228244   \n",
              "\n",
              "        frequency  Status_0.0  Status_1.0  Status_2.0  Status_4.0  \n",
              "3589     5.150000           0           0           1           0  \n",
              "3590     5.133333           0           0           1           0  \n",
              "3591     5.133333           0           0           1           0  \n",
              "3592     5.133333           0           0           1           0  \n",
              "3593     5.150000           0           0           1           0  \n",
              "...           ...         ...         ...         ...         ...  \n",
              "351140   5.050000           0           0           1           0  \n",
              "351141   3.800000           0           0           1           0  \n",
              "351142   5.033333           0           0           1           0  \n",
              "351143   5.066667           0           0           1           0  \n",
              "351144   5.050000           0           0           1           0  \n",
              "\n",
              "[222680 rows x 18 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c65899aa-04e6-4e0d-8f29-c719d7c79b26\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>編號</th>\n",
              "      <th>Date</th>\n",
              "      <th>DayNight</th>\n",
              "      <th>OrderNo</th>\n",
              "      <th>product</th>\n",
              "      <th>time</th>\n",
              "      <th>no</th>\n",
              "      <th>ProdCount</th>\n",
              "      <th>Speed</th>\n",
              "      <th>Weight</th>\n",
              "      <th>nonono</th>\n",
              "      <th>Unnamed: 12</th>\n",
              "      <th>lagProdCount</th>\n",
              "      <th>frequency</th>\n",
              "      <th>Status_0.0</th>\n",
              "      <th>Status_1.0</th>\n",
              "      <th>Status_2.0</th>\n",
              "      <th>Status_4.0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3589</th>\n",
              "      <td>2020102608:01_101181728</td>\n",
              "      <td>20201026</td>\n",
              "      <td>1</td>\n",
              "      <td>101181728</td>\n",
              "      <td>0162B00100</td>\n",
              "      <td>10/26/2020 08:01:59</td>\n",
              "      <td>D-001</td>\n",
              "      <td>392</td>\n",
              "      <td>310.0</td>\n",
              "      <td>6499.6</td>\n",
              "      <td>101181728_D-001_1</td>\n",
              "      <td>20201026_101181728_D-001_1</td>\n",
              "      <td>83</td>\n",
              "      <td>5.150000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3590</th>\n",
              "      <td>2020102608:02_101181728</td>\n",
              "      <td>20201026</td>\n",
              "      <td>1</td>\n",
              "      <td>101181728</td>\n",
              "      <td>0162B00100</td>\n",
              "      <td>10/26/2020 08:02:59</td>\n",
              "      <td>D-001</td>\n",
              "      <td>700</td>\n",
              "      <td>310.0</td>\n",
              "      <td>6499.6</td>\n",
              "      <td>101181728_D-001_1</td>\n",
              "      <td>20201026_101181728_D-001_1</td>\n",
              "      <td>392</td>\n",
              "      <td>5.133333</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3591</th>\n",
              "      <td>2020102608:03_101181728</td>\n",
              "      <td>20201026</td>\n",
              "      <td>1</td>\n",
              "      <td>101181728</td>\n",
              "      <td>0162B00100</td>\n",
              "      <td>10/26/2020 08:03:59</td>\n",
              "      <td>D-001</td>\n",
              "      <td>1008</td>\n",
              "      <td>310.0</td>\n",
              "      <td>6499.2</td>\n",
              "      <td>101181728_D-001_1</td>\n",
              "      <td>20201026_101181728_D-001_1</td>\n",
              "      <td>700</td>\n",
              "      <td>5.133333</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3592</th>\n",
              "      <td>2020102608:04_101181728</td>\n",
              "      <td>20201026</td>\n",
              "      <td>1</td>\n",
              "      <td>101181728</td>\n",
              "      <td>0162B00100</td>\n",
              "      <td>10/26/2020 08:04:59</td>\n",
              "      <td>D-001</td>\n",
              "      <td>1316</td>\n",
              "      <td>310.0</td>\n",
              "      <td>6499.2</td>\n",
              "      <td>101181728_D-001_1</td>\n",
              "      <td>20201026_101181728_D-001_1</td>\n",
              "      <td>1008</td>\n",
              "      <td>5.133333</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3593</th>\n",
              "      <td>2020102608:05_101181728</td>\n",
              "      <td>20201026</td>\n",
              "      <td>1</td>\n",
              "      <td>101181728</td>\n",
              "      <td>0162B00100</td>\n",
              "      <td>10/26/2020 08:05:59</td>\n",
              "      <td>D-001</td>\n",
              "      <td>1625</td>\n",
              "      <td>310.0</td>\n",
              "      <td>6499.0</td>\n",
              "      <td>101181728_D-001_1</td>\n",
              "      <td>20201026_101181728_D-001_1</td>\n",
              "      <td>1316</td>\n",
              "      <td>5.150000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>351140</th>\n",
              "      <td>2021111609:53_200006806</td>\n",
              "      <td>20211116</td>\n",
              "      <td>0</td>\n",
              "      <td>200006806</td>\n",
              "      <td>0162B00100</td>\n",
              "      <td>11/16/2021 09:53:11</td>\n",
              "      <td>D-005</td>\n",
              "      <td>227410</td>\n",
              "      <td>301.0</td>\n",
              "      <td>6486.4</td>\n",
              "      <td>200006806_D-005_0</td>\n",
              "      <td>20211116_200006806_D-005_0</td>\n",
              "      <td>227107</td>\n",
              "      <td>5.050000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>351141</th>\n",
              "      <td>2021111609:54_200006806</td>\n",
              "      <td>20211116</td>\n",
              "      <td>0</td>\n",
              "      <td>200006806</td>\n",
              "      <td>0162B00100</td>\n",
              "      <td>11/16/2021 09:54:11</td>\n",
              "      <td>D-005</td>\n",
              "      <td>227638</td>\n",
              "      <td>301.0</td>\n",
              "      <td>6487.8</td>\n",
              "      <td>200006806_D-005_0</td>\n",
              "      <td>20211116_200006806_D-005_0</td>\n",
              "      <td>227410</td>\n",
              "      <td>3.800000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>351142</th>\n",
              "      <td>2021111609:55_200006806</td>\n",
              "      <td>20211116</td>\n",
              "      <td>0</td>\n",
              "      <td>200006806</td>\n",
              "      <td>0162B00100</td>\n",
              "      <td>11/16/2021 09:55:11</td>\n",
              "      <td>D-005</td>\n",
              "      <td>227940</td>\n",
              "      <td>301.0</td>\n",
              "      <td>6486.2</td>\n",
              "      <td>200006806_D-005_0</td>\n",
              "      <td>20211116_200006806_D-005_0</td>\n",
              "      <td>227638</td>\n",
              "      <td>5.033333</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>351143</th>\n",
              "      <td>2021111609:56_200006806</td>\n",
              "      <td>20211116</td>\n",
              "      <td>0</td>\n",
              "      <td>200006806</td>\n",
              "      <td>0162B00100</td>\n",
              "      <td>11/16/2021 09:56:11</td>\n",
              "      <td>D-005</td>\n",
              "      <td>228244</td>\n",
              "      <td>301.0</td>\n",
              "      <td>6488.2</td>\n",
              "      <td>200006806_D-005_0</td>\n",
              "      <td>20211116_200006806_D-005_0</td>\n",
              "      <td>227940</td>\n",
              "      <td>5.066667</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>351144</th>\n",
              "      <td>2021111609:57_200006806</td>\n",
              "      <td>20211116</td>\n",
              "      <td>0</td>\n",
              "      <td>200006806</td>\n",
              "      <td>0162B00100</td>\n",
              "      <td>11/16/2021 09:57:11</td>\n",
              "      <td>D-005</td>\n",
              "      <td>228547</td>\n",
              "      <td>301.0</td>\n",
              "      <td>6489.6</td>\n",
              "      <td>200006806_D-005_0</td>\n",
              "      <td>20211116_200006806_D-005_0</td>\n",
              "      <td>228244</td>\n",
              "      <td>5.050000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>222680 rows × 18 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c65899aa-04e6-4e0d-8f29-c719d7c79b26')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c65899aa-04e6-4e0d-8f29-c719d7c79b26 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c65899aa-04e6-4e0d-8f29-c719d7c79b26');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import numpy as np\n",
        "import re\n",
        "needed = ['detail_11_position1', 'Mbatch', 'LotNo'] + [f'detail_{i}' for i in range(4, 18)]\n",
        "\n",
        "def rateTransform(data_rate, data_rate_old):\n",
        "  def concatNo(row):\n",
        "    time = str(row[0])[:-3]\n",
        "    McmNo = str(row[3])\n",
        "    Mbatch = str(row[1])\n",
        "    \n",
        "    assert type(time)  == type(Mbatch) == str, print('type must be string')\n",
        "\n",
        "    time = time.replace('/', '')\n",
        "    time = time.replace(' ', '')\n",
        "    return time+'_'+Mbatch\n",
        "  def eli_d(row):\n",
        "    element = row[0]\n",
        "    # print(element)\n",
        "    result = re.findall(r'_D-\\d\\d\\d', element)\n",
        "    # print(result)\n",
        "    element = element.replace(result[0], '')\n",
        "    # print(element)\n",
        "    row[0] = element\n",
        "    return row\n",
        "    \n",
        "\n",
        "  data_rate_filter = data_rate[needed]\n",
        "  rate_value = data_rate_filter.values\n",
        "  concatNo_list= list(map(concatNo, rate_value))\n",
        "  data_rate_filter.insert(0, '產生檢驗單號的時間', concatNo_list)\n",
        "  data_rate_filter = data_rate_filter.drop(['detail_11_position1', 'Mbatch', 'detail_17'], axis=1).reset_index(drop=True)\n",
        "\n",
        "  new_df_input = []\n",
        "  for i in range(int(len(data_rate_filter)/2)):\n",
        "    ind = i*2\n",
        "    cols = data_rate_filter.columns.tolist()\n",
        "    cols.remove('產生檢驗單號的時間')\n",
        "    cols.remove('LotNo')\n",
        "    row1 = data_rate_filter.iloc[[ind, ind+1]]\n",
        "    max_list = row1[cols].max().values.tolist()\n",
        "    min_list = row1[cols].min().values.tolist()\n",
        "    oth = row1.iloc[0][['產生檢驗單號的時間', 'LotNo']].values.tolist()\n",
        "    assert type(oth) == list, print(type(oth))\n",
        "    final_row = oth + max_list + min_list\n",
        "    \n",
        "    new_df_input.append(final_row)\n",
        "  \n",
        "  new_df = pd.DataFrame(new_df_input, \n",
        "              columns= data_rate_old.columns\n",
        "              )\n",
        "  data_rate_old = data_rate_old.apply(eli_d, axis=1)\n",
        "  merge_df = pd.concat([new_df, data_rate_old])\n",
        "\n",
        "  return merge_df\n",
        "\n",
        "def machineTransform(data_machine):\n",
        "  def eli_d(row):\n",
        "    element = row[0]\n",
        "    # print(element)\n",
        "    result = re.findall(r'_D-\\d\\d\\d', element)\n",
        "    # print(result)\n",
        "    element = element.replace(result[0], '')\n",
        "    # print(element)\n",
        "    row[0] = element\n",
        "    return row\n",
        "  data_machine = data_machine.apply(eli_d, axis=1)\n",
        "  print(data_machine)\n",
        "  data_machine = pd.get_dummies(data_machine, columns=['Status'])\n",
        "  return data_machine\n",
        "def rateTransform2(data_machine):\n",
        "  def eli_d(row):\n",
        "    element = row[0]\n",
        "    # print(element)\n",
        "    result = re.findall(r'_D-\\d\\d\\d', element)\n",
        "    # print(result)\n",
        "    element = element.replace(result[0], '')\n",
        "    # print(element)\n",
        "    row[0] = element\n",
        "    return row\n",
        "  data_machine = data_machine.apply(eli_d, axis=1)\n",
        "  # print(data_machine)\n",
        "  # data_machine = pd.get_dummies(data_machine, columns=['Status'])\n",
        "  return data_machine\n",
        "\n",
        "data_rate = rateTransform(data_rate,data_rate_old)\n",
        "\n",
        "# merge_df.to_csv('/content/drive/MyDrive/專案/羅明秀_大數據品管/merge_df.csv', index=False)\n",
        "# data_rate = rateTransform(data_rate, data_rate_old)\n",
        "data_machine = machineTransform(data_machine)\n",
        "# data_rate = rateTransform2(data_rate_old)\n",
        "data_machine\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0DzKmeBkl6jJ"
      },
      "outputs": [],
      "source": [
        "# max_std = [3.35, 2.3, 6.3, 2.77, 2.3, 3.37, 2.54, 0.42, 0.63, 0.63, 0.63, 0.63, 0.63]\n",
        "# min_std = [3.25, 2.20, 6.14, 2.63, 2.10, 3.23, 2.34, 0.38, 0.53, 0.53, 0.53, 0.53, 0.53]\n",
        "\n",
        "# def bad_or_not(r):\n",
        "#   r = r.values\n",
        "  \n",
        "#   for i in range(13):\n",
        "    \n",
        "#     if r[2+i] > max_std[i]:\n",
        "#       return 1\n",
        "#     elif r[15+i] < min_std[i]:\n",
        "#       return 1\n",
        "#     else:\n",
        "#       pass\n",
        "#   return 0\n",
        "\n",
        "# data_rate['defect'] = data_rate.apply(bad_or_not, axis=1)\n",
        "# df_copy = data_rate.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99ILUW3GmG3v"
      },
      "outputs": [],
      "source": [
        "# value = df_copy[['defect']].groupby('defect').size()\n",
        "# value.plot(kind='bar')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "id": "npH9mWsFnAFM",
        "outputId": "d0ac1954-6e70-4484-af58-146fe5706da3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 26368 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 22823 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 23567 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 26368 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 22823 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 23567 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# import seaborn as sns\n",
        "# import matplotlib.pyplot as plt\n",
        "# y = data_rate.iloc[:,2:]\n",
        "# corr = y.corr()\n",
        "# ax = sns.heatmap(\n",
        "#     corr, \n",
        "#     vmin=-1, vmax=1, center=0,\n",
        "#     cmap=sns.diverging_palette(20, 220, n=200),\n",
        "#     square=True\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVTWOOC5m1hw"
      },
      "source": [
        "#Preprocess\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3d9xlKxgo23"
      },
      "outputs": [],
      "source": [
        "def fit_package(data_machine=data_machine, data_rate=data_rate):\n",
        "  time_num = 3600\n",
        "  data_machine.set_index(\"編號\", inplace=True)\n",
        "  all_data_machineId = np.array(data_machine.index.drop_duplicates(keep='first').values)\n",
        "  data_machine.reset_index(inplace=True)\n",
        "\n",
        "  data_rate.set_index(\"產生檢驗單號的時間\", inplace=True)\n",
        "  all_data_rateId = np.array(data_rate.index.drop_duplicates(keep='first').values)\n",
        "  data_rate.reset_index(inplace=True)\n",
        "\n",
        "  print(all_data_machineId.size)\n",
        "  print(all_data_rateId.size)\n",
        "\n",
        "  pkg_num = 0\n",
        "\n",
        "  for data_rateId in all_data_rateId:\n",
        "    time_compare = time_num\n",
        "    data_machineId_compare = 0\n",
        "    for data_machineId in all_data_machineId:\n",
        "      \"\"\"\n",
        "      完全相同\n",
        "      \"\"\"\n",
        "      # if data_machineId == data_rateId:\n",
        "      #   pkg_num += 1 \n",
        "      #   globals()['x_'+str(pkg_num)] = data_machine[data_machine[\"編號\"] == data_machineId]\n",
        "      #   globals()['y_'+str(pkg_num)] = data_rate[data_rate[\"產生檢驗單號的時間\"] == data_rateId]\n",
        "      # else:\n",
        "      \"\"\"\n",
        "      完全相同&時間誤差一小時內視為同包\n",
        "      \"\"\"\n",
        "      machineId = data_machineId[14:]  \n",
        "      rateId = data_rateId[14:]\n",
        "      \n",
        "      if rateId == machineId:\n",
        "        time_machine = datetime.strptime(data_machineId[0:13], \"%Y%m%d%H:%M\")\n",
        "        time_rate = datetime.strptime(data_rateId[0:13], \"%Y%m%d%H:%M\")\n",
        "        time_diff = (time_rate - time_machine).total_seconds()\n",
        "\n",
        "        if time_diff <= 3600 and time_diff >= 0 and time_diff < time_compare:\n",
        "          data_machineId_compare = data_machineId\n",
        "          time_compare = time_diff\n",
        "            \n",
        "    if data_machineId_compare != 0:\n",
        "      pkg_num += 1 \n",
        "      # print(data_machineId_compare)\n",
        "      globals()['x_'+str(pkg_num)] = data_machine[data_machine[\"編號\"] == data_machineId_compare]\n",
        "      globals()['y_'+str(pkg_num)] = data_rate[data_rate[\"產生檢驗單號的時間\"] == data_rateId]\n",
        "      globals()['z_'+str(pkg_num)] = data_rate[\"料號\"][data_rate[\"產生檢驗單號的時間\"] == data_rateId]\n",
        "      globals()['t_'+str(pkg_num)] = pd.Series([time_compare])\n",
        "  max_pkg_num = pkg_num\n",
        "  print('Total package number:', max_pkg_num)\n",
        "  return data_machine, data_rate, max_pkg_num\n",
        "\n",
        "\n",
        "def to_sequence(data_machine, data_rate, max_pkg_num, sequence_num=100):\n",
        "  usable_pkg = 0\n",
        "  lessthan = 0\n",
        "  \n",
        "\n",
        "  for pkg_num in range(1, max_pkg_num+1):\n",
        "    rateId = str(globals()['y_'+str(pkg_num)][[\"產生檢驗單號的時間\"]].values[0][0][14:])\n",
        "    machineIndex = int(globals()['x_'+str(pkg_num)].index[0])\n",
        "    machineId = str(globals()['x_'+str(pkg_num)][[\"編號\"]].values[0][0][14:]) #17-32\n",
        "\n",
        "    for num in range(machineIndex,0,-1):\n",
        "      features = data_machine.loc[[num]][['Speed', 'frequency', 'Status_0.0', 'Status_1.0', 'Status_2.0', 'Status_4.0']]\n",
        "      if num == machineIndex:\n",
        "        globals()['x_sequence_'+str(pkg_num)] = features\n",
        "      else:\n",
        "        # print(str(data_machine[\"編號\"][num])[14:], machineId, type(str(data_machine[\"編號\"][num])[14:])==type(machineId))\n",
        "        # print('*'*200)\n",
        "        if len(globals()['x_sequence_'+str(pkg_num)]) >= sequence_num:\n",
        "          break\n",
        "        else:\n",
        "          if (str(data_machine[\"編號\"][num])[14:] == machineId) and (len(globals()['x_sequence_'+str(pkg_num)]) < sequence_num):\n",
        "          \n",
        "            globals()['x_sequence_'+str(pkg_num)] = pd.concat([globals()['x_sequence_'+str(pkg_num)], features])\n",
        "            # print(len(globals()['x_sequence_'+str(pkg_num)]))\n",
        "\n",
        "\n",
        "  for pkg_num in range(1, max_pkg_num+1):\n",
        "    if len(globals()['x_sequence_'+str(pkg_num)]) < sequence_num:\n",
        "      lessthan += 1\n",
        "    else:\n",
        "      if usable_pkg == 0:\n",
        "        first_pkg = pkg_num \n",
        "      usable_pkg += 1\n",
        "    # globals()['x_sequence_'+str(pkg_num)] = globals()['x_sequence_'+str(pkg_num)].drop([\"編號\"], axis=1)\n",
        "    globals()['y_sequence_'+str(pkg_num)] = globals()['y_'+str(pkg_num)].drop([\"產生檢驗單號的時間\",\"料號\"], axis=1)\n",
        "    globals()['z_sequence_'+str(pkg_num)] = globals()['z_'+str(pkg_num)]\n",
        "    globals()['t_sequence_'+str(pkg_num)] = globals()['t_'+str(pkg_num)]\n",
        "  \"\"\"\n",
        "  one hot encoding\n",
        "  \"\"\"\n",
        "  # for pkg_num in range(1, max_pkg_num+1):\n",
        "  #   if len(globals()['x_sequence_'+str(pkg_num)]) < sequence_num:\n",
        "  #     pass\n",
        "  #   else:\n",
        "  #     globals()['x_sequence_'+str(pkg_num)] = pd.get_dummies(globals()['x_sequence_'+str(pkg_num)]).values\n",
        "      \n",
        "\n",
        "  # print(globals()['x_sequence_'+str(first_pkg)].shape)  \n",
        "  # print(globals()['y_sequence_'+str(first_pkg)].shape)\n",
        "  # print(globals()['z_sequence_'+str(first_pkg)].shape)\n",
        "  # print(globals()['t_sequence_'+str(first_pkg)].shape)\n",
        "\n",
        "  \"\"\"\n",
        "  依序存進data & label\n",
        "  \"\"\"\n",
        "  count = 0\n",
        "  for pkg_num in range(1, max_pkg_num+1):\n",
        "    \n",
        "    if len(globals()['x_sequence_'+str(pkg_num)]) < sequence_num:\n",
        "      # print('n')\n",
        "      pass\n",
        "    else:\n",
        "      # print('y')\n",
        "      if pkg_num == first_pkg:\n",
        "\n",
        "        data = pd.DataFrame(globals()['x_sequence_'+str(pkg_num)])\n",
        "        label = pd.DataFrame(globals()['y_sequence_'+str(pkg_num)])    \n",
        "        \n",
        "        partno = pd.DataFrame(globals()['z_sequence_'+str(pkg_num)])    \n",
        "        timediff = pd.DataFrame(globals()['t_sequence_'+str(pkg_num)])\n",
        "      else:\n",
        "        count+=1\n",
        "        data = pd.concat([data, pd.DataFrame(globals()['x_sequence_'+str(pkg_num)])])\n",
        "        label = pd.concat([label, pd.DataFrame(globals()['y_sequence_'+str(pkg_num)])])\n",
        "        partno = pd.concat([partno, pd.DataFrame(globals()['z_sequence_'+str(pkg_num)])])\n",
        "        timediff = pd.concat([timediff, pd.DataFrame(globals()['t_sequence_'+str(pkg_num)])])\n",
        "      \n",
        "     \n",
        "\n",
        "  print(count)\n",
        "  data = data.values\n",
        "\n",
        "  label = label.values\n",
        "  partno = partno.values\n",
        "  timediff = timediff.values\n",
        "\n",
        "  # print(data.shape) \n",
        "  # print(label.shape) \n",
        "  # print(partno.shape) \n",
        "  # print(timediff.shape)\n",
        "\n",
        "  slide_size = 0\n",
        "  pkg_size = 0\n",
        "  data_temp = []\n",
        "  data_temp1 = []\n",
        "  label_temp = []\n",
        "\n",
        "  for pkg_num in range(1, max_pkg_num+1):\n",
        "    if len(globals()['x_sequence_'+str(pkg_num)]) < sequence_num:\n",
        "      pass\n",
        "    else: \n",
        "      data_temp.append(globals()['x_sequence_'+str(pkg_num)].values)\n",
        "      label_temp.append(globals()['y_sequence_'+str(pkg_num)].values)\n",
        "      \n",
        "      \n",
        "      # print(data[slide_size:(slide_size+sequence_num), :])\n",
        "      # print(data[slide_size:(slide_size+sequence_num), 0:3])\n",
        "      slide_size += sequence_num\n",
        "\n",
        "\n",
        "  data = np.array(data_temp)\n",
        "  label = np.array(label_temp)\n",
        "\n",
        "  # print(data.shape)\n",
        "  # print(label.shape)\n",
        "  # print(partno.shape)\n",
        "  # print(timediff.shape)\n",
        "\n",
        "  return data, label, partno, timediff\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4coUiXFLhDMH",
        "outputId": "a4c4dfc0-2eee-48fc-c1f8-303bd99debcb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "        Speed  frequency  Status_0.0  Status_1.0  Status_2.0  Status_4.0\n",
            "213721   58.0       16.4           0           1           0           0\n",
            "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
            "       Speed  frequency  Status_0.0  Status_1.0  Status_2.0  Status_4.0\n",
            "27112  317.0   1.933333           0           1           0           0\n",
            "27111  325.0   4.133333           0           1           0           0\n",
            "27110  310.0   5.150000           0           0           1           0\n",
            "27109  310.0   5.150000           0           0           1           0\n",
            "27108  310.0   5.133333           0           0           1           0\n",
            "27107  310.0   5.133333           0           0           1           0\n",
            "27106  310.0   5.166667           0           0           1           0\n",
            "27105  310.0   3.500000           0           0           1           0\n",
            "27104  325.0   1.433333           0           1           0           0\n",
            "27103  310.0   5.133333           0           0           1           0\n",
            "27102  310.0   5.166667           0           0           1           0\n",
            "27101  310.0   5.150000           0           0           1           0\n",
            "27100  310.0   5.150000           0           0           1           0\n",
            "27099  310.0   5.150000           0           0           1           0\n",
            "27098  310.0   5.100000           0           0           1           0\n",
            "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
            "        Speed  frequency  Status_0.0  Status_1.0  Status_2.0  Status_4.0\n",
            "213768  188.0   0.383333           0           0           0           1\n",
            "213767  188.0   0.600000           0           0           0           1\n",
            "213766  188.0   0.200000           0           0           0           1\n",
            "213765  188.0   0.250000           0           0           0           1\n",
            "213764  188.0   0.683333           0           0           0           1\n",
            "213763  188.0   0.550000           0           0           0           1\n",
            "213762  188.0   0.333333           0           0           0           1\n",
            "213761  188.0   0.416667           0           0           0           1\n",
            "213760  188.0   0.050000           0           0           0           1\n",
            "213759  188.0   0.366667           0           0           0           1\n",
            "213758  188.0   0.116667           0           0           0           1\n",
            "213757  188.0   0.050000           0           0           0           1\n",
            "213756  188.0   0.116667           0           0           0           1\n",
            "213755  188.0   0.233333           0           0           0           1\n",
            "213754  188.0   0.150000           0           0           0           1\n",
            "213753   22.0   0.133333           0           0           0           1\n",
            "213752   22.0   0.100000           0           0           0           1\n",
            "213751  188.0   0.133333           0           0           0           1\n",
            "213750  188.0   0.033333           0           0           0           1\n",
            "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
            "        Speed  frequency  Status_0.0  Status_1.0  Status_2.0  Status_4.0\n",
            "213768  188.0   0.383333           0           0           0           1\n",
            "213767  188.0   0.600000           0           0           0           1\n",
            "213766  188.0   0.200000           0           0           0           1\n",
            "213765  188.0   0.250000           0           0           0           1\n",
            "213764  188.0   0.683333           0           0           0           1\n",
            "213763  188.0   0.550000           0           0           0           1\n",
            "213762  188.0   0.333333           0           0           0           1\n",
            "213761  188.0   0.416667           0           0           0           1\n",
            "213760  188.0   0.050000           0           0           0           1\n",
            "213759  188.0   0.366667           0           0           0           1\n",
            "213758  188.0   0.116667           0           0           0           1\n",
            "213757  188.0   0.050000           0           0           0           1\n",
            "213756  188.0   0.116667           0           0           0           1\n",
            "213755  188.0   0.233333           0           0           0           1\n",
            "213754  188.0   0.150000           0           0           0           1\n",
            "213753   22.0   0.133333           0           0           0           1\n",
            "213752   22.0   0.100000           0           0           0           1\n",
            "213751  188.0   0.133333           0           0           0           1\n",
            "213750  188.0   0.033333           0           0           0           1\n",
            "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
            "        Speed  frequency  Status_0.0  Status_1.0  Status_2.0  Status_4.0\n",
            "120242  314.0   0.616667           0           1           0           0\n",
            "120241  315.0   0.600000           0           1           0           0\n",
            "120240  182.0   0.516667           0           0           0           1\n",
            "120239  182.0   0.033333           0           0           0           1\n",
            "120238  182.0   0.500000           0           0           0           1\n",
            "120237  182.0   0.066667           0           0           0           1\n",
            "120236   41.0   0.033333           0           0           0           1\n",
            "120235   41.0   0.283333           0           0           0           1\n",
            "120234   41.0   0.200000           0           0           0           1\n",
            "120233   41.0   0.033333           0           0           0           1\n",
            "120232   41.0   0.016667           0           0           0           1\n",
            "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
            "        Speed  frequency  Status_0.0  Status_1.0  Status_2.0  Status_4.0\n",
            "192555  367.0   1.383333           0           1           0           0\n",
            "192554  367.0   0.616667           0           1           0           0\n",
            "192553  367.0   0.666667           0           1           0           0\n",
            "192552  367.0   0.700000           0           1           0           0\n",
            "192551  184.0   0.450000           0           0           0           1\n",
            "192550   45.0   0.116667           0           0           0           1\n",
            "192549   44.0   0.133333           0           0           1           0\n",
            "192548   45.0   0.150000           0           0           0           1\n",
            "192547   45.0   0.050000           0           0           1           0\n",
            "192546   45.0   0.100000           0           0           0           1\n",
            "192545   44.0   0.033333           0           0           0           1\n",
            "192544   44.0   0.033333           0           0           0           1\n",
            "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
            "        Speed  frequency  Status_0.0  Status_1.0  Status_2.0  Status_4.0\n",
            "204702  367.0   0.850000           0           1           0           0\n",
            "204701  367.0   0.683333           0           1           0           0\n",
            "204700  367.0   0.666667           0           1           0           0\n",
            "204699  367.0   0.683333           0           1           0           0\n",
            "204698  367.0   0.800000           0           1           0           0\n",
            "204697   41.0   0.050000           0           0           0           1\n",
            "204696   41.0   0.016667           0           0           0           1\n",
            "204695   41.0   0.366667           0           0           1           0\n",
            "204694   41.0   0.133333           0           0           1           0\n",
            "204693   41.0   0.033333           0           0           0           1\n",
            "204692   41.0   0.033333           0           0           0           1\n",
            "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
            "        Speed  frequency  Status_0.0  Status_1.0  Status_2.0  Status_4.0\n",
            "182539  330.0   0.400000           0           0           1           0\n",
            "182538  346.0   0.950000           0           1           0           0\n",
            "182537  330.0   1.516667           0           0           1           0\n",
            "182536  330.0   0.733333           0           0           1           0\n",
            "182535  346.0   0.850000           0           1           0           0\n",
            "182534   44.0   0.300000           0           0           0           1\n",
            "182533   44.0   0.266667           0           0           1           0\n",
            "182532   44.0   0.083333           0           0           0           1\n",
            "182531  296.0   4.883333           0           0           0           1\n",
            "182530  330.0   5.500000           0           0           1           0\n",
            "182529  330.0   5.483333           0           0           1           0\n",
            "182528  330.0   3.216667           0           0           1           0\n",
            "182527  346.0   4.100000           0           1           0           0\n",
            "182526  330.0   5.483333           0           0           1           0\n",
            "182525  330.0   5.500000           0           0           1           0\n",
            "182524  330.0   5.500000           0           0           1           0\n",
            "182523  330.0   5.483333           0           0           1           0\n",
            "182522  330.0   5.500000           0           0           1           0\n",
            "182521  330.0   1.800000           0           0           1           0\n",
            "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
            "        Speed  frequency  Status_0.0  Status_1.0  Status_2.0  Status_4.0\n",
            "213721   58.0       16.4           0           1           0           0\n",
            "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
            "        Speed  frequency  Status_0.0  Status_1.0  Status_2.0  Status_4.0\n",
            "120243  299.0   0.733333           0           0           1           0\n",
            "120242  314.0   0.616667           0           1           0           0\n",
            "120241  315.0   0.600000           0           1           0           0\n",
            "120240  182.0   0.516667           0           0           0           1\n",
            "120239  182.0   0.033333           0           0           0           1\n",
            "120238  182.0   0.500000           0           0           0           1\n",
            "120237  182.0   0.066667           0           0           0           1\n",
            "120236   41.0   0.033333           0           0           0           1\n",
            "120235   41.0   0.283333           0           0           0           1\n",
            "120234   41.0   0.200000           0           0           0           1\n",
            "120233   41.0   0.033333           0           0           0           1\n",
            "120232   41.0   0.016667           0           0           0           1\n",
            "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "2718"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "j = 0\n",
        "for i in range(max_pkg_num):\n",
        "  \n",
        "  \n",
        "  if len(globals()['x_sequence_'+str(i+1)]) != 20:\n",
        "    print(globals()['x_sequence_'+str(i+1)])\n",
        "    print('+'*200)\n",
        "  else :\n",
        "\n",
        "    j+=1\n",
        "j"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAlYrtsHm5ma"
      },
      "source": [
        "#Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_u4pkpRXnDPw"
      },
      "source": [
        "LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "fy-yPXNym73t"
      },
      "outputs": [],
      "source": [
        "class BiLSTM_layer(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, bidirectional, batch_first=False):\n",
        "        super(BiLSTM_layer, self).__init__()\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=input_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            bidirectional=bidirectional,\n",
        "            batch_first=batch_first\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Linear(hidden_size, 26)\n",
        "        \n",
        "\n",
        "    def forward(self, inputs):\n",
        "        out, (h_n, c_n) = self.lstm(inputs, None)\n",
        "        outputs = self.fc(torch.mean(h_n.squeeze(0), dim=0))\n",
        "\n",
        "        return outputs\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyKkGpxTnFNM"
      },
      "source": [
        "Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "wmA1-2q-nCZN"
      },
      "outputs": [],
      "source": [
        "class DataEncoder(nn.Module):\n",
        "  def __init__(self, input_dim, output_dim, hidden_dim=3,dropout=0.4):\n",
        "    super(DataEncoder, self).__init__()\n",
        "    self.input_dim = input_dim\n",
        "    self.output_dim = output_dim\n",
        "    \n",
        "    self.net = nn.Sequential(nn.Linear(input_dim, hidden_dim),\n",
        "                             nn.ReLU(),\n",
        "                             nn.Dropout(dropout),\n",
        "                             nn.Linear(hidden_dim, output_dim)\n",
        "                            )\n",
        "  def forward(self, x):\n",
        "    return self.net(x)\n",
        "\n",
        "class minmax_RuleEncoder(nn.Module):\n",
        "  def __init__(self, input_dim, output_dim, hidden_dim=3,dropout=0.4):\n",
        "    super(minmax_RuleEncoder, self).__init__()\n",
        "    self.input_dim = input_dim\n",
        "    self.output_dim = output_dim\n",
        "    self.net = nn.Sequential(nn.Linear(input_dim, hidden_dim),\n",
        "                             nn.ReLU(),\n",
        "                             nn.Dropout(dropout),\n",
        "                             nn.Linear(hidden_dim, output_dim)\n",
        "                            )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.net(x)\n",
        "\n",
        "class outbound_RuleEncoder(nn.Module):\n",
        "  def __init__(self, input_dim, output_dim, hidden_dim=3,dropout=0.4):\n",
        "    super(outbound_RuleEncoder, self).__init__()\n",
        "    self.input_dim = input_dim\n",
        "    self.output_dim = output_dim\n",
        "    self.net = nn.Sequential(nn.Linear(input_dim, hidden_dim),\n",
        "                             nn.ReLU(),\n",
        "                             nn.Dropout(dropout),\n",
        "                             nn.Linear(hidden_dim, output_dim)\n",
        "                            )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.net(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "gN0057ZmOeo5",
        "outputId": "f0fa1498-a711-4903-eb09-7a6c37e13510"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-6e33d09b-0152-4550-8a8b-e1a22d558ba4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>編號</th>\n",
              "      <th>Date</th>\n",
              "      <th>DayNight</th>\n",
              "      <th>OrderNo</th>\n",
              "      <th>product</th>\n",
              "      <th>time</th>\n",
              "      <th>no</th>\n",
              "      <th>ProdCount</th>\n",
              "      <th>Speed</th>\n",
              "      <th>Status</th>\n",
              "      <th>Weight</th>\n",
              "      <th>nonono</th>\n",
              "      <th>Unnamed: 12</th>\n",
              "      <th>lagProdCount</th>\n",
              "      <th>frequency</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020102608:01_101181728</td>\n",
              "      <td>20201026</td>\n",
              "      <td>1</td>\n",
              "      <td>101181728</td>\n",
              "      <td>0162B00100</td>\n",
              "      <td>10/26/2020 08:01:59</td>\n",
              "      <td>D-001</td>\n",
              "      <td>392</td>\n",
              "      <td>310.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>6499.6</td>\n",
              "      <td>101181728_D-001_1</td>\n",
              "      <td>20201026_101181728_D-001_1</td>\n",
              "      <td>83</td>\n",
              "      <td>5.150000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020102608:02_101181728</td>\n",
              "      <td>20201026</td>\n",
              "      <td>1</td>\n",
              "      <td>101181728</td>\n",
              "      <td>0162B00100</td>\n",
              "      <td>10/26/2020 08:02:59</td>\n",
              "      <td>D-001</td>\n",
              "      <td>700</td>\n",
              "      <td>310.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>6499.6</td>\n",
              "      <td>101181728_D-001_1</td>\n",
              "      <td>20201026_101181728_D-001_1</td>\n",
              "      <td>392</td>\n",
              "      <td>5.133333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020102608:03_101181728</td>\n",
              "      <td>20201026</td>\n",
              "      <td>1</td>\n",
              "      <td>101181728</td>\n",
              "      <td>0162B00100</td>\n",
              "      <td>10/26/2020 08:03:59</td>\n",
              "      <td>D-001</td>\n",
              "      <td>1008</td>\n",
              "      <td>310.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>6499.2</td>\n",
              "      <td>101181728_D-001_1</td>\n",
              "      <td>20201026_101181728_D-001_1</td>\n",
              "      <td>700</td>\n",
              "      <td>5.133333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020102608:04_101181728</td>\n",
              "      <td>20201026</td>\n",
              "      <td>1</td>\n",
              "      <td>101181728</td>\n",
              "      <td>0162B00100</td>\n",
              "      <td>10/26/2020 08:04:59</td>\n",
              "      <td>D-001</td>\n",
              "      <td>1316</td>\n",
              "      <td>310.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>6499.2</td>\n",
              "      <td>101181728_D-001_1</td>\n",
              "      <td>20201026_101181728_D-001_1</td>\n",
              "      <td>1008</td>\n",
              "      <td>5.133333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020102608:05_101181728</td>\n",
              "      <td>20201026</td>\n",
              "      <td>1</td>\n",
              "      <td>101181728</td>\n",
              "      <td>0162B00100</td>\n",
              "      <td>10/26/2020 08:05:59</td>\n",
              "      <td>D-001</td>\n",
              "      <td>1625</td>\n",
              "      <td>310.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>6499.0</td>\n",
              "      <td>101181728_D-001_1</td>\n",
              "      <td>20201026_101181728_D-001_1</td>\n",
              "      <td>1316</td>\n",
              "      <td>5.150000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>222675</th>\n",
              "      <td>2021111609:53_200006806</td>\n",
              "      <td>20211116</td>\n",
              "      <td>0</td>\n",
              "      <td>200006806</td>\n",
              "      <td>0162B00100</td>\n",
              "      <td>11/16/2021 09:53:11</td>\n",
              "      <td>D-005</td>\n",
              "      <td>227410</td>\n",
              "      <td>301.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>6486.4</td>\n",
              "      <td>200006806_D-005_0</td>\n",
              "      <td>20211116_200006806_D-005_0</td>\n",
              "      <td>227107</td>\n",
              "      <td>5.050000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>222676</th>\n",
              "      <td>2021111609:54_200006806</td>\n",
              "      <td>20211116</td>\n",
              "      <td>0</td>\n",
              "      <td>200006806</td>\n",
              "      <td>0162B00100</td>\n",
              "      <td>11/16/2021 09:54:11</td>\n",
              "      <td>D-005</td>\n",
              "      <td>227638</td>\n",
              "      <td>301.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>6487.8</td>\n",
              "      <td>200006806_D-005_0</td>\n",
              "      <td>20211116_200006806_D-005_0</td>\n",
              "      <td>227410</td>\n",
              "      <td>3.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>222677</th>\n",
              "      <td>2021111609:55_200006806</td>\n",
              "      <td>20211116</td>\n",
              "      <td>0</td>\n",
              "      <td>200006806</td>\n",
              "      <td>0162B00100</td>\n",
              "      <td>11/16/2021 09:55:11</td>\n",
              "      <td>D-005</td>\n",
              "      <td>227940</td>\n",
              "      <td>301.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>6486.2</td>\n",
              "      <td>200006806_D-005_0</td>\n",
              "      <td>20211116_200006806_D-005_0</td>\n",
              "      <td>227638</td>\n",
              "      <td>5.033333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>222678</th>\n",
              "      <td>2021111609:56_200006806</td>\n",
              "      <td>20211116</td>\n",
              "      <td>0</td>\n",
              "      <td>200006806</td>\n",
              "      <td>0162B00100</td>\n",
              "      <td>11/16/2021 09:56:11</td>\n",
              "      <td>D-005</td>\n",
              "      <td>228244</td>\n",
              "      <td>301.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>6488.2</td>\n",
              "      <td>200006806_D-005_0</td>\n",
              "      <td>20211116_200006806_D-005_0</td>\n",
              "      <td>227940</td>\n",
              "      <td>5.066667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>222679</th>\n",
              "      <td>2021111609:57_200006806</td>\n",
              "      <td>20211116</td>\n",
              "      <td>0</td>\n",
              "      <td>200006806</td>\n",
              "      <td>0162B00100</td>\n",
              "      <td>11/16/2021 09:57:11</td>\n",
              "      <td>D-005</td>\n",
              "      <td>228547</td>\n",
              "      <td>301.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>6489.6</td>\n",
              "      <td>200006806_D-005_0</td>\n",
              "      <td>20211116_200006806_D-005_0</td>\n",
              "      <td>228244</td>\n",
              "      <td>5.050000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>222680 rows × 15 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6e33d09b-0152-4550-8a8b-e1a22d558ba4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6e33d09b-0152-4550-8a8b-e1a22d558ba4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6e33d09b-0152-4550-8a8b-e1a22d558ba4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                             編號      Date  DayNight    OrderNo     product  \\\n",
              "0       2020102608:01_101181728  20201026         1  101181728  0162B00100   \n",
              "1       2020102608:02_101181728  20201026         1  101181728  0162B00100   \n",
              "2       2020102608:03_101181728  20201026         1  101181728  0162B00100   \n",
              "3       2020102608:04_101181728  20201026         1  101181728  0162B00100   \n",
              "4       2020102608:05_101181728  20201026         1  101181728  0162B00100   \n",
              "...                         ...       ...       ...        ...         ...   \n",
              "222675  2021111609:53_200006806  20211116         0  200006806  0162B00100   \n",
              "222676  2021111609:54_200006806  20211116         0  200006806  0162B00100   \n",
              "222677  2021111609:55_200006806  20211116         0  200006806  0162B00100   \n",
              "222678  2021111609:56_200006806  20211116         0  200006806  0162B00100   \n",
              "222679  2021111609:57_200006806  20211116         0  200006806  0162B00100   \n",
              "\n",
              "                       time     no  ProdCount  Speed  Status  Weight  \\\n",
              "0       10/26/2020 08:01:59  D-001        392  310.0     2.0  6499.6   \n",
              "1       10/26/2020 08:02:59  D-001        700  310.0     2.0  6499.6   \n",
              "2       10/26/2020 08:03:59  D-001       1008  310.0     2.0  6499.2   \n",
              "3       10/26/2020 08:04:59  D-001       1316  310.0     2.0  6499.2   \n",
              "4       10/26/2020 08:05:59  D-001       1625  310.0     2.0  6499.0   \n",
              "...                     ...    ...        ...    ...     ...     ...   \n",
              "222675  11/16/2021 09:53:11  D-005     227410  301.0     2.0  6486.4   \n",
              "222676  11/16/2021 09:54:11  D-005     227638  301.0     2.0  6487.8   \n",
              "222677  11/16/2021 09:55:11  D-005     227940  301.0     2.0  6486.2   \n",
              "222678  11/16/2021 09:56:11  D-005     228244  301.0     2.0  6488.2   \n",
              "222679  11/16/2021 09:57:11  D-005     228547  301.0     2.0  6489.6   \n",
              "\n",
              "                   nonono                 Unnamed: 12  lagProdCount  frequency  \n",
              "0       101181728_D-001_1  20201026_101181728_D-001_1            83   5.150000  \n",
              "1       101181728_D-001_1  20201026_101181728_D-001_1           392   5.133333  \n",
              "2       101181728_D-001_1  20201026_101181728_D-001_1           700   5.133333  \n",
              "3       101181728_D-001_1  20201026_101181728_D-001_1          1008   5.133333  \n",
              "4       101181728_D-001_1  20201026_101181728_D-001_1          1316   5.150000  \n",
              "...                   ...                         ...           ...        ...  \n",
              "222675  200006806_D-005_0  20211116_200006806_D-005_0        227107   5.050000  \n",
              "222676  200006806_D-005_0  20211116_200006806_D-005_0        227410   3.800000  \n",
              "222677  200006806_D-005_0  20211116_200006806_D-005_0        227638   5.033333  \n",
              "222678  200006806_D-005_0  20211116_200006806_D-005_0        227940   5.066667  \n",
              "222679  200006806_D-005_0  20211116_200006806_D-005_0        228244   5.050000  \n",
              "\n",
              "[222680 rows x 15 columns]"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_machine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WG27yWd7nIWo"
      },
      "source": [
        "Net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "1Y8MmKt3nJPM"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self, input_dim, output_dim, minmax_rule_encoder, outbound_rule_encoder, data_encoder, hidden_dim=3, n_layers=1, merge='cat', skip=False, input_type='state'):\n",
        "    super(Net, self).__init__()\n",
        "    self.skip = skip\n",
        "    self.input_type = input_type\n",
        "    self.minmax_rule_encoder = minmax_rule_encoder\n",
        "    self.outbound_rule_encoder = outbound_rule_encoder\n",
        "    self.data_encoder = data_encoder\n",
        "    self.n_layers = n_layers\n",
        "    assert self.minmax_rule_encoder.input_dim ==  self.data_encoder.input_dim\n",
        "    assert self.minmax_rule_encoder.output_dim ==  self.data_encoder.output_dim\n",
        "    self.merge = merge\n",
        "    if merge == 'cat':\n",
        "      self.input_dim_decision_block = self.minmax_rule_encoder.output_dim * 3\n",
        "    elif merge == 'add':\n",
        "      self.input_dim_decision_block = self.minmax_rule_encoder.output_dim\n",
        "\n",
        "    self.net = []\n",
        "    for i in range(n_layers):\n",
        "      if i == 0:\n",
        "        in_dim = self.input_dim_decision_block\n",
        "      else:\n",
        "        in_dim = hidden_dim\n",
        "\n",
        "      if i == n_layers-1:\n",
        "        out_dim = output_dim\n",
        "      else:\n",
        "        out_dim = hidden_dim\n",
        "      \n",
        "      self.net.append(BiLSTM_layer(\n",
        "              input_size=in_dim,\n",
        "              hidden_size=64,\n",
        "              num_layers=1,\n",
        "              bidirectional=True,\n",
        "              batch_first=True\n",
        "          ))\n",
        "    self.net = nn.Sequential(*self.net)\n",
        "\n",
        "  def get_z(self, x, alpha=0.0, beta=0.0):\n",
        "    minmax_rule_z = self.minmax_rule_encoder(x)\n",
        "    outbound_rule_z = self.outbound_rule_encoder(x)\n",
        "    data_z = self.data_encoder(x)\n",
        "\n",
        "    if self.merge=='add':\n",
        "      z = alpha * minmax_rule_z + beta * outbound_rule_z + (1-alpha-beta) * data_z    \n",
        "    elif self.merge=='cat':\n",
        "      z = torch.cat((alpha*minmax_rule_z , beta*outbound_rule_z , (1-alpha-beta)*data_z), dim=-1)   \n",
        "\n",
        "    return z\n",
        "\n",
        "  def forward(self, x, alpha=0.0, beta=0.0):\n",
        "    minmax_rule_z = self.minmax_rule_encoder(x)\n",
        "    outbound_rule_z = self.outbound_rule_encoder(x)\n",
        "    data_z = self.data_encoder(x)\n",
        "\n",
        "    if self.merge=='add':\n",
        "      z = alpha*minmax_rule_z + beta*outbound_rule_z + (1-alpha-beta)*data_z   \n",
        "    elif self.merge=='cat':\n",
        "      z = torch.cat((alpha*minmax_rule_z , beta*outbound_rule_z , (1-alpha-beta)*data_z), dim=-1)  \n",
        "    else:\n",
        "      print(self.merge)\n",
        "  \n",
        "    if self.skip:\n",
        "      if self.input_type == 'seq':\n",
        "        return self.net(z) + x[:,-1,:]\n",
        "      else:\n",
        "        return self.net(z) + x    \n",
        "    else:\n",
        "      return self.net(z) \n",
        "      \n",
        "      try:\n",
        "        return self.net(z)   \n",
        "      except:\n",
        "        print(type(z))\n",
        "        print(z.shape)\n",
        "\n",
        "class DataonlyNet(nn.Module):\n",
        "  def __init__(self, input_dim, output_dim, data_encoder, hidden_dim=4, n_layers=2, skip=False, input_type='state'):\n",
        "    super(DataonlyNet, self).__init__()\n",
        "    self.skip = skip\n",
        "    self.input_type = input_type\n",
        "    self.data_encoder = data_encoder\n",
        "    self.n_layers = n_layers\n",
        "    self.input_dim_decision_block = self.data_encoder.output_dim\n",
        "\n",
        "    self.net = []\n",
        "    for i in range(n_layers):\n",
        "      if i == 0:\n",
        "        in_dim = self.input_dim_decision_block\n",
        "      else:\n",
        "        in_dim = hidden_dim\n",
        "\n",
        "      if i == n_layers-1:\n",
        "        out_dim = output_dim\n",
        "      else:\n",
        "        out_dim = hidden_dim\n",
        "\n",
        "      self.net.append(BiLSTM_layer(\n",
        "            input_size=in_dim,\n",
        "            hidden_size=64,\n",
        "            num_layers=1,\n",
        "            bidirectional=True,\n",
        "            batch_first=True\n",
        "        ))\n",
        "      \n",
        "    self.net = nn.Sequential(*self.net)\n",
        "\n",
        "  def get_z(self, x, alpha=0.0):\n",
        "    data_z = self.data_encoder(x)\n",
        "\n",
        "    return data_z\n",
        "\n",
        "  def forward(self, x, alpha=0.0):\n",
        "    data_z = self.data_encoder(x)\n",
        "    z = data_z\n",
        "\n",
        "    if self.skip:\n",
        "      if self.input_type == 'seq':\n",
        "        return self.net(z) + x[:,-1,:]\n",
        "      else:\n",
        "        return self.net(z) + x    \n",
        "    else:\n",
        "      return self.net(z)    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3F5n6qWOQeXY"
      },
      "source": [
        "#Metrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "pX1o-YLxRdfh"
      },
      "outputs": [],
      "source": [
        "# def custom_mse(y_true, y_pred, alpha, beta):\n",
        "#     alpha_loss=alpha\n",
        "#     beta_loss=beta\n",
        "    \n",
        "#     loss_task = nn.MSELoss()(y_true, y_pred)\n",
        "#     #loss_rule=  K.relu(y_pred[:,0] - 3.35)+K.relu(3.30 - y_pred[:,0])+K.relu(y_pred[:,1] - 2.3)+K.relu(2.2 - y_pred[:,1])+K.relu(y_pred[:,2] - 6.2)+K.relu(6.14 - y_pred[:,2])+K.relu(y_pred[:,3] - 2.77)+K.relu(2.63 - y_pred[:,3])+K.relu(y_pred[:,4] - 2.3)+K.relu(2.1 - y_pred[:,4])+K.relu(y_pred[:,5] - 3.37)+K.relu(3.23 - y_pred[:,5])+K.relu(y_pred[:,6] - 2.54)+K.relu(2.34 - y_pred[:,6])+K.relu(y_pred[:,7] - 0.42)+K.relu(0.38 - y_pred[:,7])+K.relu(y_pred[:,8] - 0.63)+K.relu(0.53 - y_pred[:,8])+K.relu(y_pred[:,9] - 0.63)+K.relu(0.53 - y_pred[:,9])+K.relu(y_pred[:,10] - 0.63)+K.relu(0.53 - y_pred[:,10])+K.relu(y_pred[:,11] - 0.63)+K.relu(0.53 - y_pred[:,11])+K.relu(y_pred[:,12] - 0.63)+K.relu(0.53 - y_pred[:,12])+K.relu(y_pred[:,13] - 3.35)+K.relu(3.30 - y_pred[:,13])+K.relu(y_pred[:,14] - 2.3)+K.relu(2.2 - y_pred[:,14])+K.relu(y_pred[:,15] - 6.2)+K.relu(6.14 - y_pred[:,15])+K.relu(y_pred[:,16] - 2.77)+K.relu(2.63 - y_pred[:,16])+K.relu(y_pred[:,17] - 2.3)+K.relu(2.1 - y_pred[:,17])+K.relu(y_pred[:,18] - 3.37)+K.relu(3.23 - y_pred[:,18])+K.relu(y_pred[:,19] - 2.54)+K.relu(2.34 - y_pred[:,19])+K.relu(y_pred[:,20] - 0.42)+K.relu(0.38 - y_pred[:,20])+K.relu(y_pred[:,21] - 0.63)+K.relu(0.53 - y_pred[:,21])+K.relu(y_pred[:,22] - 0.63)+K.relu(0.53 - y_pred[:,22])+K.relu(y_pred[:,23] - 0.63)+K.relu(0.53 - y_pred[:,23])+K.relu(y_pred[:,24] - 0.63)+K.relu(0.53 - y_pred[:,24])+K.relu(y_pred[:,25] - 0.63)+K.relu(0.53 - y_pred[:,25])\n",
        "#     loss_rule_minmax= F.relu(y_pred[:,13] - y_pred[:,0])+F.relu(y_pred[:,14] - y_pred[:,1])+F.relu(y_pred[:,15] - y_pred[:,2])+F.relu(y_pred[:,16] - y_pred[:,3])+F.relu(y_pred[:,17] - y_pred[:,4])+F.relu(y_pred[:,18] - y_pred[:,5])+F.relu(y_pred[:,19] - y_pred[:,6])+F.relu(y_pred[:,20] - y_pred[:,7])+F.relu(y_pred[:,21] - y_pred[:,8])+F.relu(y_pred[:,22] - y_pred[:,9])+F.relu(y_pred[:,23] - y_pred[:,10])+F.relu(y_pred[:,24] - y_pred[:,11])+F.relu(y_pred[:,25] - y_pred[:,12])\n",
        "#     loss_rule_outbound=F.relu((y_true[:,0] - 3.35)*(3.35-y_pred[:,0]))+F.relu((y_true[:,1] - 2.3)*(2.3-y_pred[:,1]))+F.relu((y_true[:,2] - 6.3)*(6.3-y_pred[:,2]))+F.relu((y_true[:,3] - 2.77)*(2.77-y_pred[:,3]))+F.relu((y_true[:,4] - 2.3)*(2.3-y_pred[:,4]))+F.relu((y_true[:,5] - 3.37)*(3.37-y_pred[:,5]))+F.relu((y_true[:,6] - 2.54)*(2.54-y_pred[:,6]))+F.relu((y_true[:,7] - 0.42)*(0.42-y_pred[:,7]))+F.relu((y_true[:,8] - 0.63)*(0.63-y_pred[:,8]))+F.relu((y_true[:,9] - 0.63)*(0.63-y_pred[:,9]))+F.relu((y_true[:,10] - 0.63)*(0.63-y_pred[:,10]))+F.relu((y_true[:,11] - 0.63)*(0.63-y_pred[:,11]))+F.relu((y_true[:,12] - 0.63)*(0.63-y_pred[:,12]))+F.relu((y_true[:,13] - 3.25)*(3.25-y_pred[:,13]))+F.relu((y_true[:,14] - 2.2)*(2.2-y_pred[:,14]))+F.relu((y_true[:,15] - 6.14)*(6.14-y_pred[:,15]))+F.relu((y_true[:,16] - 2.63)*(2.63-y_pred[:,16]))+F.relu((y_true[:,17] - 2.1)*(2.1-y_pred[:,17]))+F.relu((y_true[:,18] - 3.23)*(3.23-y_pred[:,18]))+F.relu((y_true[:,19] - 2.34)*(2.34-y_pred[:,19]))+F.relu((y_true[:,20] - 2.38)*(2.38-y_pred[:,20]))+F.relu((y_true[:,21] - 0.53)*(0.53-y_pred[:,21]))+F.relu((y_true[:,22] - 0.53)*(0.53-y_pred[:,22]))+F.relu((y_true[:,23] - 0.53)*(0.53-y_pred[:,23]))+F.relu((y_true[:,24] - 0.53)*(0.53-y_pred[:,24]))+F.relu((y_true[:,25] - 0.53)*(0.53-y_pred[:,25]))\n",
        "#     # loss_rule_outbound=loss_rule_outbound*10\n",
        "\n",
        "#     loss_rule_minmax = sum(loss_rule_minmax)\n",
        "#     loss_rule_outbound = sum(loss_rule_outbound)\n",
        "\n",
        "#     # print(y_true)\n",
        "#     # print(y_pred)\n",
        "#     # print('loss_task:', loss_task)\n",
        "#     # print('loss_rule_minmax:', loss_rule_minmax)\n",
        "#     # print('loss_rule_outbound:', loss_rule_outbound)\n",
        "\n",
        "#     # print(loss)\n",
        "#     loss= alpha_loss*loss_rule_minmax + beta_loss*loss_rule_outbound + (1-beta_loss-alpha_loss)*loss_task\n",
        "\n",
        "#     return loss\n",
        "\n",
        "def custom_mse(y_true, y_pred, alpha, beta):\n",
        "    alpha_loss=alpha\n",
        "    beta_loss=beta\n",
        "    \n",
        "    # print(y_true.shape)\n",
        "    # print(y_pred.shape)\n",
        "    loss_task = nn.MSELoss()(y_true, y_pred)\n",
        "    #loss_rule=  K.relu(y_pred[:,0] - 3.35)+K.relu(3.30 - y_pred[:,0])+K.relu(y_pred[:,1] - 2.3)+K.relu(2.2 - y_pred[:,1])+K.relu(y_pred[:,2] - 6.2)+K.relu(6.14 - y_pred[:,2])+K.relu(y_pred[:,3] - 2.77)+K.relu(2.63 - y_pred[:,3])+K.relu(y_pred[:,4] - 2.3)+K.relu(2.1 - y_pred[:,4])+K.relu(y_pred[:,5] - 3.37)+K.relu(3.23 - y_pred[:,5])+K.relu(y_pred[:,6] - 2.54)+K.relu(2.34 - y_pred[:,6])+K.relu(y_pred[:,7] - 0.42)+K.relu(0.38 - y_pred[:,7])+K.relu(y_pred[:,8] - 0.63)+K.relu(0.53 - y_pred[:,8])+K.relu(y_pred[:,9] - 0.63)+K.relu(0.53 - y_pred[:,9])+K.relu(y_pred[:,10] - 0.63)+K.relu(0.53 - y_pred[:,10])+K.relu(y_pred[:,11] - 0.63)+K.relu(0.53 - y_pred[:,11])+K.relu(y_pred[:,12] - 0.63)+K.relu(0.53 - y_pred[:,12])+K.relu(y_pred[:,13] - 3.35)+K.relu(3.30 - y_pred[:,13])+K.relu(y_pred[:,14] - 2.3)+K.relu(2.2 - y_pred[:,14])+K.relu(y_pred[:,15] - 6.2)+K.relu(6.14 - y_pred[:,15])+K.relu(y_pred[:,16] - 2.77)+K.relu(2.63 - y_pred[:,16])+K.relu(y_pred[:,17] - 2.3)+K.relu(2.1 - y_pred[:,17])+K.relu(y_pred[:,18] - 3.37)+K.relu(3.23 - y_pred[:,18])+K.relu(y_pred[:,19] - 2.54)+K.relu(2.34 - y_pred[:,19])+K.relu(y_pred[:,20] - 0.42)+K.relu(0.38 - y_pred[:,20])+K.relu(y_pred[:,21] - 0.63)+K.relu(0.53 - y_pred[:,21])+K.relu(y_pred[:,22] - 0.63)+K.relu(0.53 - y_pred[:,22])+K.relu(y_pred[:,23] - 0.63)+K.relu(0.53 - y_pred[:,23])+K.relu(y_pred[:,24] - 0.63)+K.relu(0.53 - y_pred[:,24])+K.relu(y_pred[:,25] - 0.63)+K.relu(0.53 - y_pred[:,25])\n",
        "    loss_rule_minmax= F.relu(y_pred[:,13] - y_pred[:,0])+F.relu(y_pred[:,14] - y_pred[:,1])+F.relu(y_pred[:,15] - y_pred[:,2])+F.relu(y_pred[:,16] - y_pred[:,3])+F.relu(y_pred[:,17] - y_pred[:,4])+F.relu(y_pred[:,18] - y_pred[:,5])+F.relu(y_pred[:,19] - y_pred[:,6])+F.relu(y_pred[:,20] - y_pred[:,7])+F.relu(y_pred[:,21] - y_pred[:,8])+F.relu(y_pred[:,22] - y_pred[:,9])+F.relu(y_pred[:,23] - y_pred[:,10])+F.relu(y_pred[:,24] - y_pred[:,11])+F.relu(y_pred[:,25] - y_pred[:,12])\n",
        "    loss_rule_outbound=F.relu((y_true[:,0] - 3.35)*(3.35-y_pred[:,0]))+F.relu((y_true[:,1] - 2.3)*(2.3-y_pred[:,1]))+F.relu((y_true[:,2] - 6.3)*(6.3-y_pred[:,2]))+F.relu((y_true[:,3] - 2.77)*(2.77-y_pred[:,3]))+F.relu((y_true[:,4] - 2.3)*(2.3-y_pred[:,4]))+F.relu((y_true[:,5] - 3.37)*(3.37-y_pred[:,5]))+F.relu((y_true[:,6] - 2.54)*(2.54-y_pred[:,6]))+F.relu((y_true[:,7] - 0.42)*(0.42-y_pred[:,7]))+F.relu((y_true[:,8] - 0.63)*(0.63-y_pred[:,8]))+F.relu((y_true[:,9] - 0.63)*(0.63-y_pred[:,9]))+F.relu((y_true[:,10] - 0.63)*(0.63-y_pred[:,10]))+F.relu((y_true[:,11] - 0.63)*(0.63-y_pred[:,11]))+F.relu((y_true[:,12] - 0.63)*(0.63-y_pred[:,12]))+F.relu((y_true[:,13] - 3.25)*(3.25-y_pred[:,13]))+F.relu((y_true[:,14] - 2.2)*(2.2-y_pred[:,14]))+F.relu((y_true[:,15] - 6.14)*(6.14-y_pred[:,15]))+F.relu((y_true[:,16] - 2.63)*(2.63-y_pred[:,16]))+F.relu((y_true[:,17] - 2.1)*(2.1-y_pred[:,17]))+F.relu((y_true[:,18] - 3.23)*(3.23-y_pred[:,18]))+F.relu((y_true[:,19] - 2.34)*(2.34-y_pred[:,19]))+F.relu((y_true[:,20] - 0.38)*(0.38-y_pred[:,20]))+F.relu((y_true[:,21] - 0.53)*(0.53-y_pred[:,21]))+F.relu((y_true[:,22] - 0.53)*(0.53-y_pred[:,22]))+F.relu((y_true[:,23] - 0.53)*(0.53-y_pred[:,23]))+F.relu((y_true[:,24] - 0.53)*(0.53-y_pred[:,24]))+F.relu((y_true[:,25] - 0.53)*(0.53-y_pred[:,25]))\n",
        "    loss_rule_outbound=loss_rule_outbound*10\n",
        "   \n",
        "\n",
        "    #print('alpha_loss',alpha_loss)\n",
        "    #print('beta_loss',beta_loss)\n",
        "    loss= alpha_loss*loss_rule_minmax + beta_loss*loss_rule_outbound + (1-beta_loss-alpha_loss)*loss_task\n",
        "\n",
        "    return loss\n",
        "\n",
        "\n",
        "\n",
        "# def measure_std(y_true, y_pred):\n",
        "\n",
        "#   def transform(y_pred):\n",
        "#     max_output = np.array(y_pred[:13])\n",
        "#     min_output = np.array(y_pred[13:])\n",
        "    \n",
        "#     maxmin = max_output - min_output\n",
        "#     if any(maxmin<0):\n",
        "#       return 1\n",
        "#     else :\n",
        "#       return 0\n",
        "\n",
        "#   def transform2(y):\n",
        "#     max_std = np.array([3.35, 2.3, 6.3, 2.77, 2.3, 3.37, 2.54, 0.42, 0.63, 0.63, 0.63, 0.63, 0.63])\n",
        "#     min_std = np.array([3.25, 2.20, 6.14, 2.63, 2.10, 3.23, 2.34, 0.38, 0.53, 0.53, 0.53, 0.53, 0.53])\n",
        " \n",
        "#     max_output = np.array(y[:13])\n",
        "#     min_output = np.array(y[13:])\n",
        "\n",
        "#     if any(max_output>max_std) or any(min_output < min_std):\n",
        "#       return 1 \n",
        "#     else:\n",
        "#       return 0    \n",
        "\n",
        "#   defect = {}\n",
        "  \n",
        "#   y_true = y_true.cpu().detach().tolist()\n",
        "#   y_pred = y_pred.cpu().detach().tolist()\n",
        "\n",
        "#   true_defect_np = np.array(list(map(transform2, y_true)))\n",
        "#   pred_defect_np = np.array(list(map(transform2, y_pred)))\n",
        "#   # print(true_defect_np.shape,pred_defect_np.shape)\n",
        "#   defect_np = np.array([1 if i == False else 0 for i in (true_defect_np == pred_defect_np)])\n",
        "#   # print(defect_np)\n",
        "#   minmax_np = np.array(list(map(transform, y_pred)))\n",
        "\n",
        "#   assert defect_np.shape == minmax_np.shape, print(defect_np.shape, minmax_np.shape)\n",
        "\n",
        "#   combine_np = [0 if i==0 else 1 for i in (defect_np + minmax_np)]\n",
        "\n",
        "#   defect_acc = np.count_nonzero(defect_np==0) / len(defect_np)\n",
        "#   all_acc = np.count_nonzero(combine_np==0) / len(combine_np)\n",
        "#   defect['all'] = defect_acc\n",
        "                                                                \n",
        "  \n",
        "  \n",
        "  # for i in range(y_pred.shape[0]):\n",
        "  #   # print(y_pred.shape[0])\n",
        "  #   value = y_pred[i]\n",
        "  #   for j in range(13):\n",
        "  #     if (value[j] > max_std[j]) or (value[j+13] < min_std[j]):\n",
        "  #       defect_list.append(1)\n",
        "  #       break\n",
        "  #     else:\n",
        "  #       if j == 12:\n",
        "  #         defect_list.append(0)\n",
        "  \n",
        "  # return defect\n",
        "\n",
        "def measure_std(y_true, y_pred):\n",
        "  y_true = y_true.cpu().detach().numpy()\n",
        "  y_pred = y_pred.cpu().detach().numpy()\n",
        "  \n",
        "  max_std = [3.35, 2.3, 6.3, 2.77, 2.3, 3.37, 2.54, 0.42, 0.63, 0.63, 0.63, 0.63, 0.63]\n",
        "  min_std = [3.25, 2.20, 6.14, 2.63, 2.10, 3.23, 2.34, 0.38, 0.53, 0.53, 0.53, 0.53, 0.53]\n",
        "  std = max_std + min_std\n",
        "\n",
        "  # max_std = [3.35, 2.3, 6.3, 2.77, 3.37, 2.54, 0.42, 2.3, 0.63, 0.63, 0.63, 0.63, 0.63]\n",
        "  # min_std = [3.25, 2.20, 6.14, 2.63, 3.23, 2.34, 0.38, 2.10, 0.53, 0.53, 0.53, 0.53, 0.53]\n",
        " \n",
        "  defect = []\n",
        "  acc_list = []\n",
        "  all = []\n",
        "  pred_lists = []\n",
        "  true_lists = []\n",
        "\n",
        "  for i in range(26):\n",
        "    true = y_true[:, i]\n",
        "    pred = y_pred[:, i]\n",
        "\n",
        "    pred_list = []\n",
        "    true_list = []\n",
        " \n",
        "\n",
        "    for j in range(y_pred.shape[0]):\n",
        "      if i < 13:\n",
        "   \n",
        "        [pred_list.append(1) if pred[j]>std[j] else pred_list.append(0)]\n",
        "        [true_list.append(1) if true[j]>std[j] else true_list.append(0)]   \n",
        "       \n",
        "      else:\n",
        "        [pred_list.append(1) if pred[j]<std[j] else pred_list.append(0)]\n",
        "        [true_list.append(1) if true[j]<std[j] else true_list.append(0)] \n",
        "   \n",
        "\n",
        "    pred_lists += pred_list\n",
        "    true_lists += true_list\n",
        "\n",
        "    pred_np = np.array(pred_list)\n",
        "    true_np = np.array(true_list)\n",
        "    acc = (pred_np == true_np).sum() / len(pred_np)\n",
        "    acc_list.append(acc)\n",
        "    # defect[f'feature_{5+i}'] = acc\n",
        "\n",
        "    all.append((pred_np == true_np))\n",
        "  all_np = np.array(all)\n",
        "  batch = all_np.shape[1]\n",
        "  # print(type(batch))\n",
        "  all_defect_np = np.array([1 if any(all_np[:, i]==False) else 0 for i in range(batch)])\n",
        "  all_acc = np.count_nonzero(all_defect_np==0) / len(all_defect_np)\n",
        "  \n",
        "                                                                \n",
        "  \n",
        "  max_pred = y_pred[:, :13]\n",
        "  min_pred = y_pred[:, 13:]\n",
        "\n",
        "  tfPred = max_pred >= min_pred \n",
        "\n",
        "  for i in range(13):\n",
        "    feature = tfPred[:, i]\n",
        "    # print(feature)\n",
        "    feature_acc = sum(feature) / len(feature)\n",
        "    # print(sum(tfPred), len(tfPred))\n",
        "    defect.append(feature_acc)\n",
        "    # print(feature_acc)\n",
        "\n",
        "  # for i in range(y_pred.shape[0]):\n",
        "  #   # print(y_pred.shape[0])\n",
        "  #   value = y_pred[i]\n",
        "  #   for j in range(13):\n",
        "  #     if (value[j] > max_std[j]) or (value[j+13] < min_std[j]):\n",
        "  #       defect_list.append(1)\n",
        "  #       break\n",
        "  #     else:\n",
        "  #       if j == 12:\n",
        "  #         defect_list.append(0)\n",
        "    \n",
        "  \n",
        "  return defect, all_acc, true_lists, pred_lists\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgU0WwwLnTcz"
      },
      "source": [
        "#Train & val\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "mP6icrt7nNa8"
      },
      "outputs": [],
      "source": [
        "def val(model, val_loader , device, alpha=0.0,beta=0.0):\n",
        "    ''' Validation '''\n",
        "    true_list = []\n",
        "    pred_list = []\n",
        "    val_list = []\n",
        "    avg_acc_list = []\n",
        "    defects = []\n",
        "    avg_feature_accs = []\n",
        "    record_dict = {}\n",
        "    true_onehot = []\n",
        "    pred_onehot = []\n",
        "\n",
        "    model.eval()\n",
        "  \n",
        "    with torch.no_grad():\n",
        "\n",
        "      for X_val, y_val in val_loader:\n",
        "        X_val = X_val.to(torch.float32)\n",
        "        X_val = X_val.to(device)\n",
        "       \n",
        "        y_val = y_val.to(torch.float32)\n",
        "        y_val = y_val.to(device) \n",
        " \n",
        "        y_pred= model(X_val, alpha=alpha, beta=beta)\n",
        "  \n",
        "        val_loss=custom_mse(y_val, y_pred, alpha, beta)\n",
        "        val_list.append(val_loss.sum().item())\n",
        "  \n",
        "        assert y_val.shape == y_pred.shape, print(\"shape not match\")\n",
        "  \n",
        "        defect, acc, true_lists, pred_lists = measure_std(y_val, y_pred)\n",
        "        defects.append(defect)\n",
        "        avg_acc_list.append(acc)\n",
        "        true_onehot += true_lists\n",
        "        pred_onehot += pred_lists\n",
        "        \n",
        "        true_list += y_val.tolist()\n",
        "        pred_list += y_pred.tolist()\n",
        "\n",
        "      avg_val_loss = sum(val_list) / len(val_list)\n",
        "      # record_dict['Val Loss'] = avg_val_loss\n",
        "      avg_val_acc = sum(avg_acc_list) / len(avg_acc_list)\n",
        "      # record_dict['Val Acc'] = avg_val_acc\n",
        "      for i in range(13):\n",
        "        col = np.array(defects)[:, i]\n",
        "        avg_feature_acc = sum(col) / len(col) \n",
        "        record_dict[f'Val Acc_{i}'] = avg_feature_acc\n",
        "        avg_feature_accs.append(avg_feature_acc)\n",
        "      \n",
        " \n",
        "    model.train()  \n",
        "    return avg_val_loss, avg_val_acc, record_dict, true_list, pred_list, avg_feature_accs, true_onehot, pred_onehot\n",
        "\n",
        "\n",
        "def train(model, optimizer, train_loader, device, scheduler=None, val_loader=None, alpha=0.0, beta=0.0,  epochs=1000, early_stopping_steps= 6000, type_='train', show_postfix=True ):\n",
        "  ''' Training '''\n",
        "\n",
        "  lrs = []\n",
        "  all_training_loss = []\n",
        "  all_training_acc = []\n",
        "  all_val_loss = []\n",
        "  all_val_acc = []\n",
        "  all_training_feature_acc = []\n",
        "  all_val_feature_acc = []\n",
        "  best = {}\n",
        "  best_acc = 0\n",
        "  early_stopping = 0\n",
        "  steps = 0\n",
        "  \n",
        "\n",
        "  all_steps= epochs * len(train_loader)\n",
        "\n",
        "  for epoch in range(1, epochs+1):\n",
        "\n",
        "    model.train()\n",
        "    \n",
        "    if show_postfix == True: \n",
        "      pbar = tqdm(total=len(train_loader), desc=f'Epoch{epoch}')\n",
        "    for X_train, y_train in train_loader:\n",
        "\n",
        "      X_train = X_train.to(torch.float32)\n",
        "      X_train = X_train.to(device)\n",
        "      y_train = y_train.to(torch.float32)\n",
        "      y_train = y_train.to(device)\n",
        "      #batch_train_x=torch.reshape(batch_train_x, (-1, 300))\n",
        "    \n",
        "      optimizer.zero_grad()\n",
        "      \n",
        "      beta_param  = [0.1]\n",
        "      if len(beta_param) == 1:\n",
        "        alpha_distribution = Beta(float(beta_param[0]), float(beta_param[0]))\n",
        "        beta_distribution = Beta(float(beta_param[0]), float(beta_param[0]))\n",
        "      elif len(beta_param) == 2:  \n",
        "        alpha_distribution = Beta(float(beta_param[0]), float(beta_param[1]))\n",
        "        beta_distribution = Beta(float(beta_param[0]), float(beta_param[0]))\n",
        "      alpha = alpha_distribution.sample().item()\n",
        "      # alpha=0\n",
        "      # beta=0\n",
        "      beta = beta_distribution.sample().item()\n",
        "      \n",
        "      if (alpha+beta)>=1:\n",
        "        alpha=alpha/2\n",
        "        beta=beta/2\n",
        "      \n",
        "      y_pred= model(X_train, alpha=alpha, beta=beta)\n",
        "\n",
        "      # assert y_train.shape == y_pred, print(y_train)\n",
        "\n",
        "      loss=custom_mse(y_train, y_pred, alpha, beta)\n",
        "\n",
        "      train_defect, train_acc, true_lists, pred_lists = measure_std(y_train, y_pred)\n",
        "      \n",
        "\n",
        "      all_training_loss.append(loss.sum().item())\n",
        "      all_training_acc.append(train_acc)\n",
        "      all_training_feature_acc.append(train_defect)\n",
        "  \n",
        "      loss.sum().backward()\n",
        "  \n",
        "      \n",
        "      # loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      if scheduler != None:\n",
        "        scheduler.step()\n",
        "      for param_group in optimizer.param_groups:\n",
        "          lr = param_group['lr']\n",
        "          lrs.append(lr)\n",
        "\n",
        "      if type_ != 'test':\n",
        "        assert val_loader != None, print('please enter val_loader')\n",
        "        # Validation\n",
        "        val_loss, avg_acc, record_dict, y_val, y_pred_val, val_defect, true_onehot, pred_onehot= val(model, val_loader, device, alpha=0, beta=0)\n",
        "        all_val_loss.append(val_loss)\n",
        "        all_val_acc.append(avg_acc)\n",
        "        all_val_feature_acc.append(val_defect)\n",
        "\n",
        "\n",
        "        # if val_loss < best_val_loss:\n",
        "        #   early_stopping = 1\n",
        "        #   best_val_loss = best_val_loss\n",
        "        #   pbar.set_postfix({'Epoch': epoch, 'Loss': loss , 'Val Loss' : val_loss, 'Update': 'Best Model is update!!'})\n",
        "        #   pbar.update(1)\n",
        "        #   torch.save({\n",
        "        #         'epoch': epoch,\n",
        "        #         'model_state_dict':model.state_dict(),\n",
        "        #         'optimizer_state_dict': optimizer.state_dict(),\n",
        "        #         'loss': best_val_loss\n",
        "        #       },'/content/drive/MyDrive/專案/羅明秀_大數據品管/model.pkl' )\n",
        "          \n",
        "        # else:\n",
        "        #   early_stopping += 1\n",
        "        #   pbar.set_postfix({'Epoch': epoch, 'Loss': loss , 'Val Loss' : val_loss})\n",
        "        #   pbar.update()\n",
        "        #   if early_stopping >= early_stopping_steps:\n",
        "        #     return all_training_loss, all_val_loss\n",
        "\n",
        "        # val_defect['Epoch'] = epoch\n",
        "        # val_defect['Loss'] = loss.sum().item()\n",
        "        # val_defect['Val Loss'] = val_loss\n",
        "        # val_defect['Train acc'] = train_acc\n",
        "\n",
        "        if avg_acc > best_acc:\n",
        "          best_acc = avg_acc\n",
        "          early_stopping = 1\n",
        "          best['Acc'] = best_acc\n",
        "          best['y_pred'] = y_pred_val\n",
        "          best['y_true'] = y_val\n",
        "          if show_postfix == True:\n",
        "            postfix = {'Epoch':epoch, 'LR': lr, 'Train Loss': loss.sum().item(), 'Train Acc': train_acc, 'Val loss':val_loss, 'Val Acc':avg_acc, 'Best Acc': best_acc }\n",
        "            postfix.update(record_dict)\n",
        "            pbar.set_postfix(postfix)\n",
        "            pbar.update(1)\n",
        "          # torch.save({\n",
        "          #       'epoch': epoch,\n",
        "          #       'model_state_dict':model.state_dict(),\n",
        "          #       'optimizer_state_dict': optimizer.state_dict(),\n",
        "          #       'loss': best_val_loss\n",
        "          #     },'/content/drive/MyDrive/專案/羅明秀_大數據品管/model.pkl' )\n",
        "          \n",
        "        else:\n",
        "          early_stopping += 1\n",
        "          if show_postfix == True:\n",
        "            postfix = {'Epoch':epoch, 'LR': lr, 'Train Loss': loss.sum().item(), 'Train Acc': train_acc, 'Val loss':val_loss, 'Val Acc':avg_acc, 'Best Acc': best_acc }\n",
        "            postfix.update(record_dict)\n",
        "            pbar.set_postfix(postfix)\n",
        "            pbar.update(1)\n",
        "          if early_stopping > early_stopping_steps:\n",
        "  \n",
        "            return all_training_acc, all_training_loss, all_val_acc, all_val_loss, best, lrs, all_training_feature_acc, all_val_feature_acc\n",
        "      else:\n",
        "        if show_postfix == True:\n",
        "          pbar.update(1)\n",
        "\n",
        "    if show_postfix == True:\n",
        "      pbar.close()\n",
        "      \n",
        "  if type_ == 'test':\n",
        "    return model, optimizer, lrs\n",
        "  else:\n",
        "    return all_training_acc, all_training_loss, all_val_acc, all_val_loss, best, lrs, all_training_feature_acc, all_val_feature_acc\n",
        "        \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mmh7XxM_Zc7W"
      },
      "source": [
        "#DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "0Id2YhvcZcPm"
      },
      "outputs": [],
      "source": [
        "def set_seed(myseed=42):\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "  np.random.seed(myseed)\n",
        "  torch.manual_seed(myseed)\n",
        "  if torch.cuda.is_available():\n",
        "      torch.cuda.manual_seed_all(myseed)\n",
        "\n",
        "def get_device():\n",
        "  device = \"cuda:0\" if torch.cuda.is_available() else 'cpu'\n",
        "  return device\n",
        "\n",
        "def get_dataloader(X, y, batchs= 16):\n",
        "  loader = DataLoader(TensorDataset(X, y), batch_size=batchs, shuffle=True)\n",
        "  return loader\n",
        "\n",
        "def get_model(seed, device, input_dim=6, output_dim_encoder=2, hidden_dim_encoder=64, output_dim=26, hidden_dim_db=64, n_layers=1, merge='cat'):\n",
        "  set_seed(seed)\n",
        "  minmax_rule_encoder = minmax_RuleEncoder(input_dim, output_dim_encoder, hidden_dim_encoder, dropout=0.2)\n",
        "  set_seed(seed)\n",
        "  outbound_rule_encoder = outbound_RuleEncoder(input_dim, output_dim_encoder, hidden_dim_encoder, dropout=0.2)\n",
        "  set_seed(seed)\n",
        "  data_encoder = DataEncoder(input_dim, output_dim_encoder, hidden_dim_encoder, dropout=0.2)\n",
        "  set_seed(seed)\n",
        "  model = Net(input_dim, output_dim, minmax_rule_encoder, outbound_rule_encoder, data_encoder, \n",
        "                        hidden_dim=hidden_dim_db, n_layers=n_layers, merge=merge).to(device)\n",
        "  return model\n",
        "\n",
        "\n",
        "def normalization(X_train_set, X_test_set):\n",
        "  train_reshape_data = X_train_set.reshape((-1, 6))\n",
        "  train_status = train_reshape_data[:, [2, 3, 4, 5]].reshape((-1, 20, 4))\n",
        "  train_others = train_reshape_data[:, [0, 1]]\n",
        "  test_reshape_data = X_test_set.reshape((-1, 6))\n",
        "  test_status = test_reshape_data[:, [2, 3, 4, 5]].reshape((-1, 20, 4))\n",
        "  test_others = test_reshape_data[:, [0, 1]]\n",
        "  # print(test_status)\n",
        "  scaler = MinMaxScaler()\n",
        "  train_others_std = scaler.fit_transform(train_others).reshape((-1, 20, 2))\n",
        "  test_others_std = scaler.transform(test_others).reshape((-1, 20, 2))\n",
        "\n",
        "  X_train_set = np.concatenate([train_others_std, train_status], axis=2)\n",
        "  X_test_set = np.concatenate([test_others_std, test_status], axis=2)\n",
        "  \n",
        "\n",
        "  return X_train_set, X_test_set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cNpOsTzX8a9"
      },
      "source": [
        "#Preprocess & CV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULJPz2XySVQP"
      },
      "source": [
        "get data & label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "P1u0GfqiX7Ak",
        "outputId": "b3f4312b-d521-484d-a03f-06ebd8a10aa7"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-bfc628c615aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_machine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_pkg_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_package\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_machine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartno\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimediff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_machine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_pkg_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'label:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'fit_package' is not defined"
          ]
        }
      ],
      "source": [
        "data_machine, data_rate, max_pkg_num = fit_package(data_machine, data_rate)\n",
        "\n",
        "data, label, partno, timediff = to_sequence(data_machine, data_rate, max_pkg_num, sequence_num=20)\n",
        "print('data:', data.shape)\n",
        "print('label:', label.shape)\n",
        "\n",
        "np.save('/content/drive/MyDrive/羅明秀_大數據品管/data_20.npy', data)\n",
        "np.save('/content/drive/MyDrive/羅明秀_大數據品管/label_20.npy', label)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "load(if u have saved it before)"
      ],
      "metadata": {
        "id": "8oUX8N-IrINt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.load('/content/drive/MyDrive/羅明秀_大數據品管/data_20.npy')\n",
        "label = np.load('/content/drive/MyDrive/羅明秀_大數據品管/label_20.npy')"
      ],
      "metadata": {
        "id": "ogki7l5wfFZ1"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMQOV9u3SQ7n"
      },
      "source": [
        "split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "1HGoF2a8KmOG"
      },
      "outputs": [],
      "source": [
        "#split into training & testing set\n",
        "X_train_set, X_test_set, y_train_set, y_test_set = train_test_split(data, label, random_state=42, train_size=0.9, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJ7qdMPt3NHD"
      },
      "source": [
        "model selection(optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOyxl9HgcwiH",
        "outputId": "1c76f75f-d43d-43fc-a3f3-34d9f66dfd89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rLoad:   0%|          | 0/36 [00:00<?, ?it/s]"
          ]
        }
      ],
      "source": [
        "import logging\n",
        "def get_logging(text):\n",
        "  logging.basicConfig(level=logging.DEBUG)\n",
        "  logging.info(text)\n",
        "\n",
        "def cross_val(kfold=5, alpha=0.1, beta=0.1, show_postfix=True):\n",
        "  device = get_device()\n",
        "  ks = KFold(n_splits=kfold, random_state=42, shuffle=True)\n",
        "  len_ = np.array(range(X_train_set.shape[0]))\n",
        "\n",
        "\n",
        "  cv_loss = []\n",
        "  cv_acc = []\n",
        "  cv_best = {}\n",
        "  cv_record = {}\n",
        "\n",
        "  last_accs = []\n",
        "  last_losses = []\n",
        "\n",
        "  # cross validation\n",
        "  for idx, index in enumerate(ks.split(len_)):\n",
        "    \n",
        "    get_logging(f'Start Training CV {idx}')\n",
        "    train_index, val_index = index\n",
        "    X_train = X_train_set[train_index, :, :]\n",
        "    # print(X_train)\n",
        "    X_val = X_train_set[val_index, :, :]\n",
        "    X_train, X_val = normalization(X_train, X_val )\n",
        "    \n",
        "    # print(X_val)\n",
        "    # print(X_train)\n",
        "    X_train = torch.tensor(X_train)\n",
        "    X_val = torch.tensor(X_val)\n",
        "    y_train = torch.tensor(y_train_set[train_index,  :])\n",
        "    y_val = torch.tensor(y_train_set[val_index, :])\n",
        "    # print('X_train:', X_train)\n",
        "    # print('y_train:', y_train)\n",
        "    # print('X_val:', X_val)\n",
        "    # print('y_val:', y_val)\n",
        "    train_loader = get_dataloader(X_train, y_train)\n",
        "    val_loader = get_dataloader(X_val, y_val)\n",
        "    model = get_model(seed=42, device=device)\n",
        "\n",
        "\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=0.01)\n",
        "    scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\n",
        "\n",
        "    all_training_acc, all_training_loss, all_val_acc, all_val_loss, best, lrs, all_training_feature_acc, all_val_feature_acc = train(model=model, \n",
        "                                                                        scheduler=scheduler,\n",
        "                                                                        optimizer=optimizer,\n",
        "                                                                        train_loader=train_loader, \n",
        "                                                                        val_loader=val_loader,\n",
        "                                                                        early_stopping_steps = 2000,\n",
        "                                                                        alpha = alpha,\n",
        "                                                                        beta = beta, \n",
        "                                                                        device=device,\n",
        "                                                                        show_postfix = show_postfix, \n",
        "                                                                        type_=None)\n",
        "    # cv_loss.append(best_val_loss)\n",
        "    best_acc = best['Acc']\n",
        "    cv_acc.append(best_acc)\n",
        "    cv_best[f'cv{idx}'] = best\n",
        "    cv_record[f'train_acc_cv{idx}'] = all_training_acc\n",
        "    cv_record[f'val_acc_cv{idx}'] = all_val_acc\n",
        "    cv_record[f'train_loss_cv{idx}'] = all_training_loss\n",
        "    cv_record[f'val_loss_cv{idx}'] = all_val_loss\n",
        "    cv_record[f'train_feature_acc{idx}'] = all_training_feature_acc\n",
        "    cv_record[f'val_feature_acc{idx}'] = all_val_feature_acc\n",
        "\n",
        "    get_logging(f'Best Accuracy: {best_acc}')\n",
        "    get_logging(f'Finish Training CV {idx}\\n')\n",
        "\n",
        "    last_accs.append(all_val_acc[-1])\n",
        "    last_losses.append(all_val_loss[-1])\n",
        "    \n",
        "    break\n",
        "  \n",
        "  avg_last_acc = sum(last_accs) / len(last_accs)\n",
        "  avg_last_loss = sum(last_losses) / len(last_losses)\n",
        "\n",
        "  return cv_record, avg_last_acc, avg_last_loss\n",
        "\n",
        "\n",
        "def search_alpha_beta(show_postfix):\n",
        "  alphas = [i/10 for i in range(0, 11, 2)]\n",
        "  betas = [i/10 for i in range(0, 11, 2)]\n",
        "  all_acc = []\n",
        "  best_acc = -1\n",
        "  best_alpha = -1\n",
        "  best_beta = -1\n",
        "  \n",
        "  with tqdm(total=len(alphas)*len(betas), desc='Load') as pbar:\n",
        "    for i in alphas:\n",
        "\n",
        "      # certain alpha vs all beta\n",
        "      alpha_acc = []\n",
        "      for j in betas:\n",
        "        cv_reord, avg_last_acc, avg_last_loss = cross_val(kfold=5, alpha=i, beta=j, show_postfix=False)\n",
        "        alpha_acc.append(avg_last_acc)\n",
        "        if avg_last_acc > best_acc:\n",
        "          best_alpha = i\n",
        "          best_beta = j\n",
        "          best_acc = avg_last_acc\n",
        "        pbar.set_postfix({'Alpha':i, 'Beta': j, 'Accuracy': avg_last_acc, 'Best': f'{best_alpha} {best_beta} {best_acc}'})\n",
        "        pbar.update(1)\n",
        "      all_acc.append(alpha_acc)\n",
        "      #row=alpha values, columns=beta values\n",
        "\n",
        "    np.save('/content/drive/MyDrive/羅明秀_大數據品管/all_acc.npy', np.array(all_acc))\n",
        "    # you could use the numpy array to print 3D chart\n",
        "\n",
        "    print('Best Alpha:', best_alpha)\n",
        "    print('Best Beta:', best_beta)\n",
        "    print('Best Accuracy:', best_acc)\n",
        "\n",
        "\n",
        "\n",
        "search_alpha_beta(show_postfix=False)\n",
        "  \n",
        "\n",
        "  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47mwQh3nA-7-"
      },
      "outputs": [],
      "source": [
        "#save data\n",
        "with open('/content/drive/MyDrive/專案/羅明秀_大數據品管/acc.json', 'w') as f:\n",
        " json.dump(cv_record, f)\n",
        "\n",
        "avg_cv_acc = sum(cv_acc) / len(cv_acc)\n",
        "print('\\n CV Accuracy:\\n', avg_cv_acc)\n",
        "\n",
        "# import json \n",
        "# with open('/content/drive/MyDrive/專案/羅明秀_大數據品管/acc.json', newline='') as f:\n",
        "  # data = json.load(f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BxroidGErRpm"
      },
      "outputs": [],
      "source": [
        "# which cv\n",
        "cv = 0\n",
        "train_acc = cv_record[f'train_acc_cv{cv}']\n",
        "val_acc = cv_record[f'val_acc_cv{cv}']\n",
        "train_loss = cv_record[f'train_loss_cv{cv}']\n",
        "val_loss = cv_record[f'val_loss_cv{cv}']\n",
        "plt.figure(figsize=(20, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_acc, label='Train')\n",
        "plt.plot(val_acc, label='Val')\n",
        "plt.title(f'CV = {cv}')\n",
        "plt.legend()\n",
        "plt.xlabel('Round(Each Batch)')\n",
        "plt.ylabel('Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(train_loss, label='Train')\n",
        "plt.plot(val_loss, label='Val')\n",
        "\n",
        "plt.title(f'CV = {cv}')\n",
        "plt.legend()\n",
        "plt.xlabel('Round(Each Batch)')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vZTMU3V6ab5o"
      },
      "outputs": [],
      "source": [
        "cv = 0\n",
        "feature = 12\n",
        "train_f = cv_record[f'train_feature_acc{cv}']\n",
        "val_f = cv_record[f'val_feature_acc{cv}']\n",
        "train_feature_acc = np.array(train_f)[:, feature]\n",
        "val_feature_acc = np.array(val_f)[:, feature]\n",
        "\n",
        "plt.plot(train_feature_acc, label='Train')\n",
        "plt.plot(val_feature_acc, label ='Val' )\n",
        "plt.legend()\n",
        "plt.title(f'Cv={cv}, Feature={feature}')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Round(Each Batch)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYRgWgBC4POe"
      },
      "source": [
        "#start training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.load('/content/drive/MyDrive/羅明秀_大數據品管/data_20.npy').reshape((-1, 20, 6))\n",
        "label = np.load('/content/drive/MyDrive/羅明秀_大數據品管/label_20.npy')\n",
        "\n",
        "#split into training & testing set\n",
        "X_train_set, X_test_set, y_train_set, y_test_set = train_test_split(data, label, random_state=42, train_size=0.9, shuffle=True)\n"
      ],
      "metadata": {
        "id": "smKnGsCrIS-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uoXvl2jk4ObA",
        "outputId": "d0c37f43-51d9-4119-e0ac-aacb503275ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch1: 100%|██████████| 153/153 [00:04<00:00, 36.91it/s]\n",
            "Epoch2: 100%|██████████| 153/153 [00:02<00:00, 62.44it/s]\n",
            "Epoch3: 100%|██████████| 153/153 [00:02<00:00, 64.24it/s]\n",
            "Epoch4: 100%|██████████| 153/153 [00:02<00:00, 61.99it/s]\n",
            "Epoch5: 100%|██████████| 153/153 [00:02<00:00, 63.07it/s]\n",
            "Epoch6: 100%|██████████| 153/153 [00:02<00:00, 64.91it/s]\n",
            "Epoch7: 100%|██████████| 153/153 [00:02<00:00, 64.30it/s]\n",
            "Epoch8: 100%|██████████| 153/153 [00:02<00:00, 64.85it/s]\n",
            "Epoch9: 100%|██████████| 153/153 [00:02<00:00, 64.13it/s]\n",
            "Epoch10: 100%|██████████| 153/153 [00:02<00:00, 65.05it/s]\n",
            "Epoch11: 100%|██████████| 153/153 [00:02<00:00, 64.90it/s]\n",
            "Epoch12: 100%|██████████| 153/153 [00:02<00:00, 64.82it/s]\n",
            "Epoch13: 100%|██████████| 153/153 [00:02<00:00, 64.85it/s]\n",
            "Epoch14: 100%|██████████| 153/153 [00:02<00:00, 64.33it/s]\n",
            "Epoch15: 100%|██████████| 153/153 [00:02<00:00, 63.85it/s]\n",
            "Epoch16: 100%|██████████| 153/153 [00:02<00:00, 64.58it/s]\n",
            "Epoch17: 100%|██████████| 153/153 [00:02<00:00, 64.74it/s]\n",
            "Epoch18: 100%|██████████| 153/153 [00:02<00:00, 64.82it/s]\n",
            "Epoch19: 100%|██████████| 153/153 [00:02<00:00, 64.48it/s]\n",
            "Epoch20: 100%|██████████| 153/153 [00:02<00:00, 64.76it/s]\n",
            "Epoch21: 100%|██████████| 153/153 [00:02<00:00, 66.65it/s]\n",
            "Epoch22: 100%|██████████| 153/153 [00:02<00:00, 65.63it/s]\n",
            "Epoch23: 100%|██████████| 153/153 [00:02<00:00, 65.12it/s]\n",
            "Epoch24: 100%|██████████| 153/153 [00:02<00:00, 65.37it/s]\n",
            "Epoch25: 100%|██████████| 153/153 [00:02<00:00, 64.47it/s]\n",
            "Epoch26: 100%|██████████| 153/153 [00:02<00:00, 63.94it/s]\n",
            "Epoch27: 100%|██████████| 153/153 [00:02<00:00, 64.76it/s]\n",
            "Epoch28: 100%|██████████| 153/153 [00:02<00:00, 63.81it/s]\n",
            "Epoch29: 100%|██████████| 153/153 [00:02<00:00, 65.48it/s]\n",
            "Epoch30: 100%|██████████| 153/153 [00:02<00:00, 64.33it/s]\n",
            "Epoch31: 100%|██████████| 153/153 [00:02<00:00, 64.29it/s]\n",
            "Epoch32: 100%|██████████| 153/153 [00:02<00:00, 63.98it/s]\n",
            "Epoch33: 100%|██████████| 153/153 [00:02<00:00, 64.87it/s]\n",
            "Epoch34: 100%|██████████| 153/153 [00:02<00:00, 64.20it/s]\n",
            "Epoch35: 100%|██████████| 153/153 [00:02<00:00, 65.83it/s]\n",
            "Epoch36: 100%|██████████| 153/153 [00:02<00:00, 65.50it/s]\n",
            "Epoch37: 100%|██████████| 153/153 [00:02<00:00, 64.31it/s]\n",
            "Epoch38: 100%|██████████| 153/153 [00:02<00:00, 66.04it/s]\n",
            "Epoch39: 100%|██████████| 153/153 [00:02<00:00, 65.75it/s]\n",
            "Epoch40: 100%|██████████| 153/153 [00:02<00:00, 64.29it/s]\n",
            "Epoch41: 100%|██████████| 153/153 [00:02<00:00, 64.73it/s]\n",
            "Epoch42: 100%|██████████| 153/153 [00:02<00:00, 64.93it/s]\n",
            "Epoch43: 100%|██████████| 153/153 [00:02<00:00, 65.36it/s]\n",
            "Epoch44: 100%|██████████| 153/153 [00:02<00:00, 65.03it/s]\n",
            "Epoch45: 100%|██████████| 153/153 [00:02<00:00, 65.42it/s]\n",
            "Epoch46: 100%|██████████| 153/153 [00:02<00:00, 65.65it/s]\n",
            "Epoch47: 100%|██████████| 153/153 [00:02<00:00, 64.39it/s]\n",
            "Epoch48: 100%|██████████| 153/153 [00:02<00:00, 64.85it/s]\n",
            "Epoch49: 100%|██████████| 153/153 [00:02<00:00, 65.08it/s]\n",
            "Epoch50: 100%|██████████| 153/153 [00:02<00:00, 64.85it/s]\n",
            "Epoch51: 100%|██████████| 153/153 [00:02<00:00, 64.75it/s]\n",
            "Epoch52: 100%|██████████| 153/153 [00:02<00:00, 64.55it/s]\n",
            "Epoch53: 100%|██████████| 153/153 [00:02<00:00, 63.21it/s]\n",
            "Epoch54: 100%|██████████| 153/153 [00:02<00:00, 65.14it/s]\n",
            "Epoch55: 100%|██████████| 153/153 [00:02<00:00, 64.07it/s]\n",
            "Epoch56: 100%|██████████| 153/153 [00:03<00:00, 44.22it/s]\n",
            "Epoch57: 100%|██████████| 153/153 [00:05<00:00, 27.63it/s]\n",
            "Epoch58: 100%|██████████| 153/153 [00:02<00:00, 58.55it/s]\n",
            "Epoch59: 100%|██████████| 153/153 [00:02<00:00, 65.14it/s]\n",
            "Epoch60: 100%|██████████| 153/153 [00:02<00:00, 64.70it/s]\n",
            "Epoch61: 100%|██████████| 153/153 [00:02<00:00, 65.27it/s]\n",
            "Epoch62: 100%|██████████| 153/153 [00:02<00:00, 64.66it/s]\n",
            "Epoch63: 100%|██████████| 153/153 [00:02<00:00, 65.44it/s]\n",
            "Epoch64: 100%|██████████| 153/153 [00:02<00:00, 63.62it/s]\n",
            "Epoch65: 100%|██████████| 153/153 [00:02<00:00, 65.97it/s]\n",
            "Epoch66: 100%|██████████| 153/153 [00:02<00:00, 65.88it/s]\n",
            "Epoch67: 100%|██████████| 153/153 [00:02<00:00, 64.42it/s]\n",
            "Epoch68: 100%|██████████| 153/153 [00:02<00:00, 63.55it/s]\n",
            "Epoch69: 100%|██████████| 153/153 [00:02<00:00, 65.48it/s]\n",
            "Epoch70: 100%|██████████| 153/153 [00:02<00:00, 64.41it/s]\n",
            "Epoch71: 100%|██████████| 153/153 [00:02<00:00, 65.28it/s]\n",
            "Epoch72: 100%|██████████| 153/153 [00:02<00:00, 64.96it/s]\n",
            "Epoch73: 100%|██████████| 153/153 [00:02<00:00, 64.83it/s]\n",
            "Epoch74: 100%|██████████| 153/153 [00:02<00:00, 64.90it/s]\n",
            "Epoch75: 100%|██████████| 153/153 [00:02<00:00, 65.52it/s]\n",
            "Epoch76: 100%|██████████| 153/153 [00:02<00:00, 65.30it/s]\n",
            "Epoch77: 100%|██████████| 153/153 [00:02<00:00, 63.40it/s]\n",
            "Epoch78: 100%|██████████| 153/153 [00:02<00:00, 64.71it/s]\n",
            "Epoch79: 100%|██████████| 153/153 [00:02<00:00, 64.24it/s]\n",
            "Epoch80: 100%|██████████| 153/153 [00:02<00:00, 64.29it/s]\n",
            "Epoch81: 100%|██████████| 153/153 [00:02<00:00, 65.27it/s]\n",
            "Epoch82: 100%|██████████| 153/153 [00:02<00:00, 65.29it/s]\n",
            "Epoch83: 100%|██████████| 153/153 [00:02<00:00, 63.86it/s]\n",
            "Epoch84: 100%|██████████| 153/153 [00:02<00:00, 64.77it/s]\n",
            "Epoch85: 100%|██████████| 153/153 [00:02<00:00, 65.02it/s]\n",
            "Epoch86: 100%|██████████| 153/153 [00:02<00:00, 64.53it/s]\n",
            "Epoch87: 100%|██████████| 153/153 [00:02<00:00, 65.31it/s]\n",
            "Epoch88: 100%|██████████| 153/153 [00:02<00:00, 66.03it/s]\n",
            "Epoch89: 100%|██████████| 153/153 [00:02<00:00, 65.25it/s]\n",
            "Epoch90: 100%|██████████| 153/153 [00:02<00:00, 63.39it/s]\n",
            "Epoch91: 100%|██████████| 153/153 [00:02<00:00, 64.74it/s]\n",
            "Epoch92: 100%|██████████| 153/153 [00:02<00:00, 65.03it/s]\n",
            "Epoch93: 100%|██████████| 153/153 [00:02<00:00, 65.18it/s]\n",
            "Epoch94: 100%|██████████| 153/153 [00:02<00:00, 65.33it/s]\n",
            "Epoch95: 100%|██████████| 153/153 [00:02<00:00, 64.35it/s]\n",
            "Epoch96: 100%|██████████| 153/153 [00:02<00:00, 63.99it/s]\n",
            "Epoch97: 100%|██████████| 153/153 [00:02<00:00, 64.14it/s]\n",
            "Epoch98: 100%|██████████| 153/153 [00:02<00:00, 63.18it/s]\n",
            "Epoch99: 100%|██████████| 153/153 [00:02<00:00, 63.46it/s]\n",
            "Epoch100: 100%|██████████| 153/153 [00:02<00:00, 62.38it/s]\n",
            "Epoch101: 100%|██████████| 153/153 [00:03<00:00, 39.39it/s]\n",
            "Epoch102: 100%|██████████| 153/153 [00:03<00:00, 45.86it/s]\n",
            "Epoch103: 100%|██████████| 153/153 [00:02<00:00, 63.77it/s]\n",
            "Epoch104: 100%|██████████| 153/153 [00:02<00:00, 65.28it/s]\n",
            "Epoch105: 100%|██████████| 153/153 [00:02<00:00, 64.77it/s]\n",
            "Epoch106: 100%|██████████| 153/153 [00:02<00:00, 65.56it/s]\n",
            "Epoch107: 100%|██████████| 153/153 [00:02<00:00, 65.79it/s]\n",
            "Epoch108: 100%|██████████| 153/153 [00:02<00:00, 65.97it/s]\n",
            "Epoch109: 100%|██████████| 153/153 [00:02<00:00, 64.88it/s]\n",
            "Epoch110: 100%|██████████| 153/153 [00:02<00:00, 64.16it/s]\n",
            "Epoch111: 100%|██████████| 153/153 [00:02<00:00, 64.97it/s]\n",
            "Epoch112: 100%|██████████| 153/153 [00:02<00:00, 65.44it/s]\n",
            "Epoch113: 100%|██████████| 153/153 [00:02<00:00, 62.97it/s]\n",
            "Epoch114: 100%|██████████| 153/153 [00:02<00:00, 64.62it/s]\n",
            "Epoch115: 100%|██████████| 153/153 [00:02<00:00, 63.52it/s]\n",
            "Epoch116: 100%|██████████| 153/153 [00:02<00:00, 64.36it/s]\n",
            "Epoch117: 100%|██████████| 153/153 [00:02<00:00, 63.96it/s]\n",
            "Epoch118: 100%|██████████| 153/153 [00:02<00:00, 64.45it/s]\n",
            "Epoch119: 100%|██████████| 153/153 [00:02<00:00, 64.21it/s]\n",
            "Epoch120: 100%|██████████| 153/153 [00:02<00:00, 63.42it/s]\n",
            "Epoch121: 100%|██████████| 153/153 [00:02<00:00, 63.32it/s]\n",
            "Epoch122: 100%|██████████| 153/153 [00:02<00:00, 65.28it/s]\n",
            "Epoch123: 100%|██████████| 153/153 [00:02<00:00, 64.84it/s]\n",
            "Epoch124: 100%|██████████| 153/153 [00:02<00:00, 64.40it/s]\n",
            "Epoch125: 100%|██████████| 153/153 [00:02<00:00, 65.76it/s]\n",
            "Epoch126: 100%|██████████| 153/153 [00:02<00:00, 65.13it/s]\n",
            "Epoch127: 100%|██████████| 153/153 [00:02<00:00, 65.13it/s]\n",
            "Epoch128: 100%|██████████| 153/153 [00:02<00:00, 64.67it/s]\n",
            "Epoch129: 100%|██████████| 153/153 [00:02<00:00, 65.03it/s]\n",
            "Epoch130: 100%|██████████| 153/153 [00:02<00:00, 64.34it/s]\n",
            "Epoch131: 100%|██████████| 153/153 [00:02<00:00, 64.83it/s]\n",
            "Epoch132: 100%|██████████| 153/153 [00:02<00:00, 65.57it/s]\n",
            "Epoch133: 100%|██████████| 153/153 [00:02<00:00, 64.98it/s]\n",
            "Epoch134: 100%|██████████| 153/153 [00:02<00:00, 64.53it/s]\n",
            "Epoch135: 100%|██████████| 153/153 [00:02<00:00, 65.73it/s]\n",
            "Epoch136: 100%|██████████| 153/153 [00:02<00:00, 64.87it/s]\n",
            "Epoch137: 100%|██████████| 153/153 [00:02<00:00, 65.04it/s]\n",
            "Epoch138: 100%|██████████| 153/153 [00:02<00:00, 64.70it/s]\n",
            "Epoch139: 100%|██████████| 153/153 [00:02<00:00, 64.86it/s]\n",
            "Epoch140: 100%|██████████| 153/153 [00:02<00:00, 64.80it/s]\n",
            "Epoch141: 100%|██████████| 153/153 [00:02<00:00, 64.84it/s]\n",
            "Epoch142: 100%|██████████| 153/153 [00:02<00:00, 65.56it/s]\n",
            "Epoch143: 100%|██████████| 153/153 [00:02<00:00, 64.00it/s]\n",
            "Epoch144: 100%|██████████| 153/153 [00:02<00:00, 64.46it/s]\n",
            "Epoch145: 100%|██████████| 153/153 [00:02<00:00, 64.54it/s]\n",
            "Epoch146: 100%|██████████| 153/153 [00:02<00:00, 64.72it/s]\n",
            "Epoch147: 100%|██████████| 153/153 [00:02<00:00, 65.29it/s]\n",
            "Epoch148: 100%|██████████| 153/153 [00:02<00:00, 64.68it/s]\n",
            "Epoch149: 100%|██████████| 153/153 [00:02<00:00, 64.84it/s]\n",
            "Epoch150: 100%|██████████| 153/153 [00:02<00:00, 65.27it/s]\n",
            "Epoch151: 100%|██████████| 153/153 [00:02<00:00, 65.32it/s]\n",
            "Epoch152: 100%|██████████| 153/153 [00:02<00:00, 63.94it/s]\n",
            "Epoch153: 100%|██████████| 153/153 [00:02<00:00, 65.20it/s]\n",
            "Epoch154: 100%|██████████| 153/153 [00:02<00:00, 63.19it/s]\n",
            "Epoch155: 100%|██████████| 153/153 [00:02<00:00, 64.40it/s]\n",
            "Epoch156: 100%|██████████| 153/153 [00:02<00:00, 64.24it/s]\n",
            "Epoch157: 100%|██████████| 153/153 [00:02<00:00, 63.87it/s]\n",
            "Epoch158: 100%|██████████| 153/153 [00:02<00:00, 65.32it/s]\n",
            "Epoch159: 100%|██████████| 153/153 [00:02<00:00, 65.50it/s]\n",
            "Epoch160: 100%|██████████| 153/153 [00:02<00:00, 65.14it/s]\n",
            "Epoch161: 100%|██████████| 153/153 [00:02<00:00, 64.08it/s]\n",
            "Epoch162: 100%|██████████| 153/153 [00:02<00:00, 64.04it/s]\n",
            "Epoch163: 100%|██████████| 153/153 [00:02<00:00, 63.31it/s]\n",
            "Epoch164: 100%|██████████| 153/153 [00:02<00:00, 64.97it/s]\n",
            "Epoch165: 100%|██████████| 153/153 [00:02<00:00, 64.89it/s]\n",
            "Epoch166: 100%|██████████| 153/153 [00:02<00:00, 65.39it/s]\n",
            "Epoch167: 100%|██████████| 153/153 [00:02<00:00, 63.58it/s]\n",
            "Epoch168: 100%|██████████| 153/153 [00:02<00:00, 65.18it/s]\n",
            "Epoch169: 100%|██████████| 153/153 [00:02<00:00, 65.95it/s]\n",
            "Epoch170: 100%|██████████| 153/153 [00:02<00:00, 65.65it/s]\n",
            "Epoch171: 100%|██████████| 153/153 [00:02<00:00, 64.69it/s]\n",
            "Epoch172: 100%|██████████| 153/153 [00:02<00:00, 65.07it/s]\n",
            "Epoch173: 100%|██████████| 153/153 [00:02<00:00, 65.61it/s]\n",
            "Epoch174: 100%|██████████| 153/153 [00:02<00:00, 64.43it/s]\n",
            "Epoch175: 100%|██████████| 153/153 [00:02<00:00, 65.64it/s]\n",
            "Epoch176: 100%|██████████| 153/153 [00:02<00:00, 65.52it/s]\n",
            "Epoch177: 100%|██████████| 153/153 [00:02<00:00, 65.18it/s]\n",
            "Epoch178: 100%|██████████| 153/153 [00:02<00:00, 65.29it/s]\n",
            "Epoch179: 100%|██████████| 153/153 [00:02<00:00, 64.16it/s]\n",
            "Epoch180: 100%|██████████| 153/153 [00:02<00:00, 64.53it/s]\n",
            "Epoch181: 100%|██████████| 153/153 [00:02<00:00, 65.82it/s]\n",
            "Epoch182: 100%|██████████| 153/153 [00:02<00:00, 64.95it/s]\n",
            "Epoch183: 100%|██████████| 153/153 [00:02<00:00, 64.49it/s]\n",
            "Epoch184: 100%|██████████| 153/153 [00:02<00:00, 65.12it/s]\n",
            "Epoch185: 100%|██████████| 153/153 [00:02<00:00, 65.85it/s]\n",
            "Epoch186: 100%|██████████| 153/153 [00:02<00:00, 66.22it/s]\n",
            "Epoch187: 100%|██████████| 153/153 [00:02<00:00, 65.37it/s]\n",
            "Epoch188: 100%|██████████| 153/153 [00:02<00:00, 65.16it/s]\n",
            "Epoch189: 100%|██████████| 153/153 [00:02<00:00, 64.17it/s]\n",
            "Epoch190: 100%|██████████| 153/153 [00:02<00:00, 64.53it/s]\n",
            "Epoch191: 100%|██████████| 153/153 [00:02<00:00, 64.85it/s]\n",
            "Epoch192: 100%|██████████| 153/153 [00:02<00:00, 63.85it/s]\n",
            "Epoch193: 100%|██████████| 153/153 [00:02<00:00, 65.21it/s]\n",
            "Epoch194: 100%|██████████| 153/153 [00:02<00:00, 64.51it/s]\n",
            "Epoch195: 100%|██████████| 153/153 [00:02<00:00, 65.84it/s]\n",
            "Epoch196: 100%|██████████| 153/153 [00:02<00:00, 64.09it/s]\n",
            "Epoch197: 100%|██████████| 153/153 [00:02<00:00, 65.12it/s]\n",
            "Epoch198: 100%|██████████| 153/153 [00:02<00:00, 64.59it/s]\n",
            "Epoch199: 100%|██████████| 153/153 [00:02<00:00, 63.77it/s]\n",
            "Epoch200: 100%|██████████| 153/153 [00:02<00:00, 65.00it/s]\n"
          ]
        }
      ],
      "source": [
        "X_train_set, X_test_set = normalization(X_train_set, X_test_set)\n",
        "train_loader = get_dataloader(torch.tensor(X_train_set), torch.tensor(y_train_set))\n",
        "\n",
        "device = get_device()\n",
        "model = get_model(seed=42, device=device)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.01)\n",
        "\n",
        "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999) \n",
        "model, optimizer, lrs = train(model=model, optimizer=optimizer, scheduler=scheduler, train_loader=train_loader, alpha=0.1, device=device, epochs=200, type_='test')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "L1MokDUZoWi1",
        "outputId": "5c5e3f9f-9123-42ca-937d-bd2660d04110"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f2a3d1ae390>]"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(lrs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Chjv8pu-3Ugy"
      },
      "source": [
        "testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5c1cCh43Teb",
        "outputId": "5862a070-bac2-42c9-fc90-fa6b8d1c5e9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing Accuracy:\n",
            "0.9448529411764706\n"
          ]
        }
      ],
      "source": [
        "test_loader = get_dataloader(torch.tensor(X_test_set), torch.tensor(y_test_set))\n",
        "avg_test_loss, avg_acc, defect, y_test, y_pred, feature_acc, true_onehot, pred_onehot = val(model, test_loader, device)\n",
        "print('Testing Accuracy:')\n",
        "print(avg_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "confusion matrix"
      ],
      "metadata": {
        "id": "mtaufOWxRJZG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YGj6AX_Zus1n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "7ff75bf3-21a6-456b-bffe-7f2f996b87ff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Confusion Matrix')"
            ]
          },
          "metadata": {},
          "execution_count": 46
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "grid = confusion_matrix(true_onehot, pred_onehot)\n",
        "fig, ax = plt.subplots()\n",
        "for (j,i),label in np.ndenumerate(grid):\n",
        "  ax.text(i,j,label,ha='center',va='center')\n",
        "ax.imshow(grid, cmap = 'tab20c')\n",
        "ax.set_xticks([1, 0])\n",
        "ax.set_yticks([1, 0])\n",
        "ax.set_xlabel('Predict')\n",
        "ax.set_ylabel('True')\n",
        "ax.set_title('Confusion Matrix')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "true_onehot == pred_onehot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRMpVcUGPf-8",
        "outputId": "a4bfd3d0-83e6-4805-cd74-5c16c9f18cc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8c7122URcG_O",
        "outputId": "2d60af13-718b-4048-ac18-424f874daba9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ],
      "source": [
        "y_pred_np = np.array(y_pred)\n",
        "max_pred = y_pred_np[:, :13]\n",
        "min_pred = y_pred_np[:, 13:]\n",
        "(max_pred < min_pred).sum(axis=0)\n",
        "# max_pred[:, 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yaO9ZRhPv_sh",
        "outputId": "4de2e26d-931b-4c78-d58f-39099639984a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tensor([[[7.7305e-01, 3.2524e-02, 1.0000e+00],\n",
            "         [7.3759e-01, 1.2557e-01, 2.0000e+00],\n",
            "         [7.3759e-01, 1.2680e-01, 2.0000e+00],\n",
            "         ...,\n",
            "         [7.3759e-01, 1.2721e-01, 2.0000e+00],\n",
            "         [7.3759e-01, 1.6468e-03, 2.0000e+00],\n",
            "         [7.7305e-01, 1.4821e-02, 1.0000e+00]],\n",
            "\n",
            "        [[7.7305e-01, 1.1198e-01, 1.0000e+00],\n",
            "         [7.3759e-01, 1.2639e-01, 2.0000e+00],\n",
            "         [7.3759e-01, 1.2680e-01, 2.0000e+00],\n",
            "         ...,\n",
            "         [7.3759e-01, 9.6336e-02, 2.0000e+00],\n",
            "         [7.7305e-01, 1.0416e-01, 1.0000e+00],\n",
            "         [7.3759e-01, 1.2639e-01, 2.0000e+00]],\n",
            "\n",
            "        [[7.9433e-01, 1.3668e-01, 2.0000e+00],\n",
            "         [7.9433e-01, 7.9045e-02, 2.0000e+00],\n",
            "         [8.3452e-01, 3.8287e-02, 1.0000e+00],\n",
            "         ...,\n",
            "         [7.9433e-01, 1.3627e-01, 2.0000e+00],\n",
            "         [7.9433e-01, 1.3668e-01, 2.0000e+00],\n",
            "         [7.9433e-01, 3.8699e-02, 2.0000e+00]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[8.0142e-01, 5.8460e-02, 1.0000e+00],\n",
            "         [7.6123e-01, 1.3215e-01, 2.0000e+00],\n",
            "         [7.6123e-01, 1.3133e-01, 2.0000e+00],\n",
            "         ...,\n",
            "         [7.6123e-01, 1.3215e-01, 2.0000e+00],\n",
            "         [7.6123e-01, 1.3215e-01, 2.0000e+00],\n",
            "         [7.6123e-01, 1.3133e-01, 2.0000e+00]],\n",
            "\n",
            "        [[7.7305e-01, 1.1569e-01, 1.0000e+00],\n",
            "         [7.3759e-01, 1.2680e-01, 2.0000e+00],\n",
            "         [7.3759e-01, 6.5459e-02, 2.0000e+00],\n",
            "         ...,\n",
            "         [7.3759e-01, 1.2762e-01, 2.0000e+00],\n",
            "         [7.3759e-01, 1.2598e-01, 2.0000e+00],\n",
            "         [7.3759e-01, 1.2680e-01, 2.0000e+00]],\n",
            "\n",
            "        [[7.3759e-01, 1.2762e-01, 2.0000e+00],\n",
            "         [7.3759e-01, 1.2557e-01, 2.0000e+00],\n",
            "         [7.3759e-01, 4.4874e-02, 2.0000e+00],\n",
            "         ...,\n",
            "         [7.3759e-01, 1.2680e-01, 2.0000e+00],\n",
            "         [7.3759e-01, 1.2680e-01, 2.0000e+00],\n",
            "         [7.3759e-01, 1.2680e-01, 2.0000e+00]]], dtype=torch.float64), tensor([[3.3061, 2.2700, 6.2744, 2.7206, 2.3000, 3.3700, 2.5033, 0.4000, 0.6220,\n",
            "         0.6230, 0.6290, 0.6250, 0.6230, 3.2589, 2.2200, 6.1968, 2.6886, 2.1602,\n",
            "         3.3306, 2.3400, 0.4000, 0.5590, 0.5560, 0.5580, 0.5650, 0.5590],\n",
            "        [3.2945, 2.2600, 6.2380, 2.7212, 2.2139, 3.3700, 2.3985, 0.4000, 0.5390,\n",
            "         0.5420, 0.5440, 0.5420, 0.5360, 3.2856, 2.2500, 6.2028, 2.6939, 2.2011,\n",
            "         3.3469, 2.3650, 0.4000, 0.5350, 0.5350, 0.5320, 0.5370, 0.5350],\n",
            "        [3.2800, 2.2400, 6.2300, 2.7700, 2.2500, 3.3400, 2.3700, 0.4000, 0.5560,\n",
            "         0.5680, 0.5790, 0.5790, 0.5640, 3.2800, 2.2300, 6.2200, 2.7200, 2.1900,\n",
            "         3.3200, 2.3400, 0.4000, 0.5350, 0.5530, 0.5390, 0.5460, 0.5390],\n",
            "        [3.2953, 2.2500, 6.2372, 2.7247, 2.2423, 3.3600, 2.4000, 0.4000, 0.6070,\n",
            "         0.6140, 0.5870, 0.5910, 0.5790, 3.2880, 2.2400, 6.2202, 2.6830, 2.1842,\n",
            "         3.3465, 2.3860, 0.4000, 0.5720, 0.5900, 0.5570, 0.5630, 0.5510],\n",
            "        [3.2996, 2.2400, 6.2601, 2.7229, 2.2505, 3.3600, 2.3673, 0.4000, 0.5530,\n",
            "         0.5400, 0.5560, 0.5570, 0.5600, 3.2858, 2.2200, 6.2214, 2.6964, 2.1945,\n",
            "         3.3478, 2.3503, 0.4000, 0.5350, 0.5360, 0.5520, 0.5500, 0.5590],\n",
            "        [3.2930, 2.2600, 6.2028, 2.7151, 2.1800, 3.3600, 2.4419, 0.4000, 0.5600,\n",
            "         0.5600, 0.5540, 0.5430, 0.5580, 3.2863, 2.2500, 6.1921, 2.6746, 2.1573,\n",
            "         3.3464, 2.3516, 0.4000, 0.5580, 0.5530, 0.5500, 0.5390, 0.5530],\n",
            "        [3.2900, 2.2600, 6.2370, 2.7051, 2.2000, 3.3555, 2.4474, 0.4000, 0.5930,\n",
            "         0.5840, 0.5850, 0.6070, 0.5900, 3.2696, 2.2300, 6.1952, 2.6980, 2.1700,\n",
            "         3.3359, 2.4016, 0.4000, 0.5730, 0.5740, 0.5710, 0.5800, 0.5870],\n",
            "        [3.2978, 2.2600, 6.2513, 2.7166, 2.2105, 3.3600, 2.4334, 0.4000, 0.5990,\n",
            "         0.6110, 0.6090, 0.6060, 0.6050, 3.2702, 2.2300, 6.2162, 2.7110, 2.1862,\n",
            "         3.3436, 2.4325, 0.4000, 0.5870, 0.6040, 0.6070, 0.6010, 0.6040],\n",
            "        [3.3026, 2.2700, 6.2541, 2.7120, 2.1997, 3.3600, 2.4165, 0.4000, 0.5730,\n",
            "         0.5660, 0.5500, 0.5720, 0.5670, 3.2744, 2.2400, 6.2185, 2.7092, 2.1979,\n",
            "         3.3500, 2.4156, 0.4000, 0.5660, 0.5520, 0.5460, 0.5520, 0.5610],\n",
            "        [3.2915, 2.2600, 6.2668, 2.7207, 2.1900, 3.3675, 2.4618, 0.4000, 0.5880,\n",
            "         0.5750, 0.5900, 0.6010, 0.6070, 3.2765, 2.2500, 6.2215, 2.6869, 2.1817,\n",
            "         3.3454, 2.4475, 0.4000, 0.5720, 0.5740, 0.5880, 0.5980, 0.6040],\n",
            "        [3.3100, 2.2600, 6.2500, 2.7700, 2.2700, 3.3300, 2.5000, 0.4000, 0.5840,\n",
            "         0.5990, 0.6100, 0.5990, 0.5930, 3.2500, 2.2100, 6.2100, 2.7000, 2.1900,\n",
            "         3.3100, 2.3400, 0.4000, 0.5300, 0.5360, 0.5360, 0.5320, 0.5320],\n",
            "        [3.2832, 2.2600, 6.2406, 2.7420, 2.1988, 3.3550, 2.4147, 0.4000, 0.5840,\n",
            "         0.5840, 0.5760, 0.5770, 0.5730, 3.2695, 2.2300, 6.2134, 2.7174, 2.1700,\n",
            "         3.3395, 2.3716, 0.4000, 0.5760, 0.5780, 0.5750, 0.5660, 0.5670],\n",
            "        [3.3100, 2.2600, 6.2529, 2.7065, 2.1924, 3.3684, 2.4696, 0.4000, 0.6130,\n",
            "         0.6120, 0.5980, 0.6160, 0.6130, 3.2681, 2.2200, 6.2190, 2.6961, 2.1800,\n",
            "         3.3514, 2.4367, 0.4000, 0.6050, 0.6060, 0.5910, 0.6110, 0.6080],\n",
            "        [3.2925, 2.2700, 6.2900, 2.7603, 2.2600, 3.3400, 2.4700, 0.4000, 0.6260,\n",
            "         0.6160, 0.6190, 0.6280, 0.6190, 3.2565, 2.2300, 6.1800, 2.6800, 2.1800,\n",
            "         3.3249, 2.3700, 0.4000, 0.5360, 0.5380, 0.5440, 0.5340, 0.5300],\n",
            "        [3.2809, 2.2500, 6.2462, 2.7352, 2.2161, 3.3505, 2.4065, 0.4000, 0.5800,\n",
            "         0.5800, 0.5830, 0.5860, 0.5800, 3.2741, 2.2400, 6.2063, 2.7292, 2.1999,\n",
            "         3.3436, 2.3882, 0.4000, 0.5630, 0.5570, 0.5620, 0.5510, 0.5660],\n",
            "        [3.2917, 2.2600, 6.2648, 2.7329, 2.2468, 3.3500, 2.3736, 0.4000, 0.5490,\n",
            "         0.5490, 0.5500, 0.5450, 0.5510, 3.2770, 2.2500, 6.2274, 2.6899, 2.1956,\n",
            "         3.3415, 2.3460, 0.4000, 0.5370, 0.5320, 0.5350, 0.5430, 0.5450]],\n",
            "       dtype=torch.float64)]\n"
          ]
        }
      ],
      "source": [
        "test_loader = get_dataloader(torch.tensor(X_test_set), torch.tensor(y_test_set))\n",
        "for i in test_loader:\n",
        "  print(i)\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89YBYG-Ocy6l",
        "outputId": "229cce18-d7fe-4e97-a1a7-54c47b98624c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.41177893, 0.41219869, 0.41219175, 0.41219437, 0.41190058,\n",
              "       0.4115926 , 0.41175729, 0.41158119, 0.4121587 , 0.41219258,\n",
              "       0.41219088, 0.41218719, 0.41219449, 0.4115932 , 0.41159305,\n",
              "       0.41177142, 0.41219369, 0.4121927 , 0.41219428, 0.41157928,\n",
              "       0.41220042, 0.41156924, 0.41219461, 0.41158819, 0.4115932 ,\n",
              "       0.41148409, 0.411174  , 0.4117775 , 0.41177684, 0.41218477,\n",
              "       0.4115966 , 0.41214541, 0.41219619, 0.411594  , 0.41159323,\n",
              "       0.41159308, 0.41117519, 0.41159239, 0.41159162, 0.41157952,\n",
              "       0.41177589, 0.41159287, 0.41217956, 0.41159546, 0.41177893,\n",
              "       0.41177675, 0.41189983, 0.41159311, 0.41159454, 0.41219717,\n",
              "       0.41219375, 0.41216567, 0.41220018, 0.41159332, 0.41159797,\n",
              "       0.4117789 , 0.411309  , 0.41219735, 0.41158891, 0.41159475,\n",
              "       0.41219553, 0.41220149, 0.41159141, 0.41219437, 0.41128469,\n",
              "       0.41219184, 0.41159785, 0.41129139, 0.41215968, 0.41215709,\n",
              "       0.41219682, 0.41218898, 0.41159394, 0.411769  , 0.41159949,\n",
              "       0.41159678, 0.41129827, 0.41159371, 0.41159096, 0.41159478,\n",
              "       0.41156626, 0.41218674, 0.4111723 , 0.41158491, 0.41219297,\n",
              "       0.41219047, 0.41218984, 0.41177171, 0.41217613, 0.41159412,\n",
              "       0.4121581 , 0.41219175, 0.41219813, 0.4115918 , 0.41178107,\n",
              "       0.41218945, 0.41158971, 0.41186607, 0.41216466, 0.41158962,\n",
              "       0.41219223, 0.41116422, 0.41134408, 0.41219434, 0.41156662,\n",
              "       0.41156963, 0.41218567, 0.41116652, 0.41159493, 0.41218227,\n",
              "       0.41160116, 0.41215762, 0.41159195, 0.4121967 , 0.41214573,\n",
              "       0.4115901 , 0.41219431, 0.41218933, 0.41148224, 0.41214705,\n",
              "       0.41219047, 0.41215724, 0.41178149, 0.41186556, 0.41219431,\n",
              "       0.41128257, 0.41220018, 0.41219881, 0.4117783 , 0.41219449,\n",
              "       0.41159219, 0.41159537, 0.4113211 , 0.41219008, 0.4121981 ,\n",
              "       0.41219616, 0.41214749, 0.41221368, 0.4121944 , 0.41216493,\n",
              "       0.41218996, 0.41190588, 0.41219854, 0.41157138, 0.41190001,\n",
              "       0.41219214, 0.41159126, 0.41159365, 0.41219351, 0.41219449,\n",
              "       0.41219291, 0.41177821, 0.41159481, 0.41216236, 0.4115966 ,\n",
              "       0.41177967, 0.4121958 , 0.41148442, 0.41130021, 0.41220024,\n",
              "       0.41219866, 0.41178247, 0.41218933, 0.41216496, 0.41219386,\n",
              "       0.41219324, 0.41219601, 0.41159037, 0.4117333 , 0.41216153,\n",
              "       0.41219765, 0.41219196, 0.41176328, 0.41159323, 0.41159165,\n",
              "       0.41218871, 0.41219461, 0.41158739, 0.41216046, 0.41219124,\n",
              "       0.41159317, 0.41116494, 0.4115943 , 0.412164  , 0.4117803 ,\n",
              "       0.41219434, 0.41219437, 0.4115915 , 0.41177684, 0.41220039,\n",
              "       0.41219458, 0.41219449, 0.4121626 , 0.41159377, 0.41117191,\n",
              "       0.41159543, 0.41215691, 0.411589  , 0.41178051, 0.41159812,\n",
              "       0.41219264, 0.4121843 , 0.41219452, 0.41218668, 0.41159141,\n",
              "       0.41217867, 0.41177338, 0.41176262, 0.4121871 , 0.41127786,\n",
              "       0.41219002, 0.41159335, 0.4115907 , 0.41189858, 0.41219437,\n",
              "       0.41218302, 0.41158924, 0.41215527, 0.41219431, 0.41219494,\n",
              "       0.41177681, 0.41159448, 0.41158885, 0.4115679 , 0.41158849,\n",
              "       0.4117842 , 0.41177589, 0.41159123, 0.41160223, 0.41160047,\n",
              "       0.41158995, 0.41219509, 0.41220599, 0.4121798 , 0.41218904,\n",
              "       0.411782  , 0.41214675, 0.41159111, 0.411596  , 0.41159406,\n",
              "       0.4115909 , 0.41219288, 0.4115918 , 0.41177335, 0.41220286,\n",
              "       0.41159409, 0.41218433, 0.41177839, 0.41177845, 0.41219795,\n",
              "       0.41220129, 0.41159165, 0.41159546, 0.41159162, 0.4115912 ,\n",
              "       0.41220143, 0.4112865 , 0.41177854, 0.41159296, 0.41218865,\n",
              "       0.4115822 , 0.41176727, 0.41128397, 0.41159752, 0.41159552,\n",
              "       0.41176203, 0.41159028, 0.41159216, 0.41177785, 0.41178337,\n",
              "       0.41216022, 0.41177779])"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ],
      "source": [
        "max_pred[:, -6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oReUN6Y0vuO4",
        "outputId": "2ede9804-b261-4aae-b0af-d2d0a87eabc2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.39069158, 0.39126682, 0.39126042, 0.39126649, 0.39088932,\n",
              "       0.39121163, 0.39126495, 0.39122349, 0.39129612, 0.39126626,\n",
              "       0.39128155, 0.39127988, 0.39126644, 0.39121166, 0.39121297,\n",
              "       0.39125186, 0.3912645 , 0.39126602, 0.39126199, 0.39122623,\n",
              "       0.39126986, 0.39124498, 0.39126641, 0.39120635, 0.39121324,\n",
              "       0.39087728, 0.3906377 , 0.39069316, 0.39069232, 0.3912783 ,\n",
              "       0.39121166, 0.39130422, 0.39126623, 0.39121225, 0.391213  ,\n",
              "       0.39121294, 0.39063966, 0.39121342, 0.39121148, 0.39122495,\n",
              "       0.39069325, 0.39121351, 0.39127195, 0.39121351, 0.39069557,\n",
              "       0.39069277, 0.39089158, 0.39121237, 0.39121348, 0.39126492,\n",
              "       0.39126664, 0.391303  , 0.39126754, 0.39121327, 0.39121374,\n",
              "       0.3906962 , 0.39083204, 0.39126632, 0.39121327, 0.39121124,\n",
              "       0.39126176, 0.3912839 , 0.3912119 , 0.39126647, 0.39085737,\n",
              "       0.39126283, 0.39121413, 0.39087349, 0.39130098, 0.39130008,\n",
              "       0.39126399, 0.39128035, 0.39121363, 0.39125749, 0.39121136,\n",
              "       0.39121178, 0.39083537, 0.39121345, 0.39121327, 0.39121303,\n",
              "       0.39124712, 0.39127925, 0.39063606, 0.39122501, 0.39126593,\n",
              "       0.39126059, 0.39127946, 0.39125612, 0.39127451, 0.39121261,\n",
              "       0.39130035, 0.39126047, 0.39126569, 0.39121065, 0.39069536,\n",
              "       0.3912802 , 0.39122438, 0.39092267, 0.39130169, 0.3912254 ,\n",
              "       0.39126378, 0.39065635, 0.39069119, 0.39126647, 0.39124697,\n",
              "       0.39124802, 0.39127749, 0.39064711, 0.3912124 , 0.39126819,\n",
              "       0.39121652, 0.39130235, 0.39121208, 0.39126712, 0.39130452,\n",
              "       0.39121261, 0.3912667 , 0.39128011, 0.39088047, 0.39131156,\n",
              "       0.39126059, 0.39130014, 0.39069593, 0.3909227 , 0.39126205,\n",
              "       0.39085957, 0.39126763, 0.39126855, 0.39069188, 0.39126629,\n",
              "       0.39121231, 0.3912138 , 0.39084157, 0.39125994, 0.39126742,\n",
              "       0.3912676 , 0.39131224, 0.3912738 , 0.39126658, 0.3912963 ,\n",
              "       0.39125979, 0.39088884, 0.39126775, 0.39124686, 0.39089027,\n",
              "       0.39126036, 0.39121419, 0.39121222, 0.39126393, 0.39126641,\n",
              "       0.3912659 , 0.39068601, 0.39121366, 0.39130247, 0.39121336,\n",
              "       0.39069319, 0.39126557, 0.39087927, 0.39083347, 0.3912622 ,\n",
              "       0.39126688, 0.39069679, 0.39128017, 0.39129788, 0.39126578,\n",
              "       0.39126551, 0.39126083, 0.39121118, 0.39074463, 0.39130014,\n",
              "       0.39126438, 0.39126357, 0.39126253, 0.39121339, 0.39121148,\n",
              "       0.39127985, 0.39126641, 0.39122543, 0.39130995, 0.39128041,\n",
              "       0.391213  , 0.39064553, 0.39121318, 0.39130145, 0.39069593,\n",
              "       0.39126647, 0.39126199, 0.39121327, 0.39070493, 0.39126995,\n",
              "       0.39126858, 0.39126638, 0.39130241, 0.39121228, 0.39063311,\n",
              "       0.39121258, 0.39129999, 0.39121333, 0.39069441, 0.39121497,\n",
              "       0.3912605 , 0.39125797, 0.39126629, 0.39127848, 0.39121184,\n",
              "       0.39126942, 0.39125609, 0.39125946, 0.39125708, 0.39086598,\n",
              "       0.39125985, 0.39121407, 0.39121124, 0.39089108, 0.39126205,\n",
              "       0.39127013, 0.39120701, 0.3912943 , 0.39126202, 0.39126781,\n",
              "       0.39069235, 0.39121312, 0.39120549, 0.3912445 , 0.39120743,\n",
              "       0.39069581, 0.39125621, 0.39121148, 0.39121783, 0.39121753,\n",
              "       0.39121222, 0.39126018, 0.39127022, 0.3912721 , 0.39128196,\n",
              "       0.39069581, 0.391312  , 0.39121142, 0.3912133 , 0.39121324,\n",
              "       0.39121428, 0.39126575, 0.39121145, 0.39125466, 0.39126885,\n",
              "       0.39121097, 0.39127386, 0.39125791, 0.39069283, 0.39126915,\n",
              "       0.39127016, 0.39121151, 0.39121276, 0.39121148, 0.39121181,\n",
              "       0.39128387, 0.39086553, 0.39069307, 0.39121318, 0.39127976,\n",
              "       0.39121649, 0.39069664, 0.39085719, 0.3912138 , 0.39121297,\n",
              "       0.39069897, 0.3912057 , 0.39121246, 0.39068913, 0.39069486,\n",
              "       0.39129317, 0.39069554])"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ],
      "source": [
        "min_pred[:,-6]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}